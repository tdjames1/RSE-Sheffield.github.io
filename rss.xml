<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>RSE at Sheffield</title><link>http://rse.shef.ac.uk/</link><description>RSE at Sheffield</description><atom:link href="http://rse.shef.ac.uk/rss.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><lastBuildDate>Tue, 23 May 2017 08:38:32 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Research Software Engineer in High Performance Computing</title><link>http://rse.shef.ac.uk/blog/research_software_engineer_in_high_performance_computing/</link><dc:creator>Paul Richmond</dc:creator><description>&lt;div&gt;&lt;p&gt;A job opportunity within the RSE Sheffield group is available under the job title of "Research Software Engineer in High Performance Computing (HPC) enabled Multi-Scale Modelling".&lt;/p&gt;
&lt;p&gt;The purpose of the Research Software Engineer post is to enhance The University’s capability and expertise in developing Research Software. This role will be based in the newly formed &lt;a href="http://rse.shef.ac.uk/"&gt;Research Software Engineering group&lt;/a&gt;, which aims to improve all aspects of research software including reproducibility, usability, efficiency and correctness.&lt;/p&gt;
&lt;p&gt;The primary function of this role is to support the EC funded CompBioMed project. A user-driven Centre of Excellence in Computational Biomedicine, to nurture and promote the uptake and exploitation of high performance computing within the biomedical modelling community. &lt;/p&gt;
&lt;p&gt;The post is fixed-term with an end date of 30 September 2019. The deadline for applications is 19th June 2017.&lt;/p&gt;
&lt;h3&gt;Links and More Information&lt;/h3&gt;
&lt;p&gt;&lt;a href="http://www.jobs.ac.uk/job/BBN749/research-software-engineer-in-high-performance-computing-hpc-enabled-multi-scale-modelling/"&gt;Jobs.ac.uk posting&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://jobs.shef.ac.uk/sap/bc/webdynpro/sap/hrrcf_a_posting_apply?PARAM=cG9zdF9pbnN0X2d1aWQ9MzMwNjJBRkQ4MDQ5MUVFNzhGOEY4MkE0ODgzRjg4MEYmY2FuZF90eXBlPUVYVA%3d%3d&amp;amp;sap-client=400&amp;amp;sap-language=EN&amp;amp;sap-accessibility=X&amp;amp;sap-ep-themeroot=%2fSAP%2fPUBLIC%2fBC%2fUR%2fuos#"&gt;University of Sheffield Application Link&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;</description><category>jobs</category><guid>http://rse.shef.ac.uk/blog/research_software_engineer_in_high_performance_computing/</guid><pubDate>Mon, 22 May 2017 17:30:00 GMT</pubDate></item><item><title>Sheffield Code First:girls</title><link>http://rse.shef.ac.uk/blog/sheffield-code-firstgirls/</link><dc:creator>Tania Allard</dc:creator><description>&lt;div&gt;&lt;p&gt;&lt;img alt="python1" src="http://rse.shef.ac.uk/images/CF_python1.jpg"&gt;&lt;/p&gt;
&lt;p&gt;Anyone working on any STEM area knows, as a fact, that we are facing a digital and technical skills gap.  In the governement's digital strategy &lt;a href="http://www.bbc.co.uk/news/business-36510266"&gt;report&lt;/a&gt; last year it
was highlighted that we would need an extra 745,000 workers with digital skills by 2017, as 90% of jobs require digital skills to some degree.
On top of this, many technical areas suffer a diversity deficit (cultural and gender based).
With the UK being among the European countries with the smaller number of female
professionals in STEM areas.&lt;/p&gt;
&lt;p&gt;Being this a rather complex problem, many people and organisations work hard to provide a solution to this issue.  Some approaches adopted by such individuals and organisations are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Encourage the hiring of highly skilled immigrants&lt;/li&gt;
&lt;li&gt;Provide wider support for underrepresented minorities&lt;/li&gt;
&lt;li&gt;Leverage inclusive and encouraging environments for those who
demonstrate an interest in STEM areas&lt;/li&gt;
&lt;li&gt;Support and train those willing to make a career change/or follow non-traditonal career paths&lt;/li&gt;
&lt;li&gt;Approach the new generations and provide them with useful skills that would help them
make an informed career choice&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;... and the list goes on.&lt;/p&gt;
&lt;p&gt;I do believe, however, that the most fruitful approach is to work with the upcoming generations and provide them with useful technical and personal skills early on. This would not only make them better qualified for their future but would enable them to make informed decisions with regards to their professional future.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.codefirstgirls.org.uk"&gt;Code First: girls&lt;/a&gt; is a multi-award organization that aims to tackle the gender imbalance in three ways: training women, building a strong and supportive community, and helping companies to train, recruit, and retain their female force.&lt;/p&gt;
&lt;p&gt;Belonging to a minority within STEM has lead me to take an active role as an equality and diversity ambassador, which eventually lead me to volunteer as a Python instructor for the Code First courses.&lt;/p&gt;
&lt;p&gt;Over the course of 8 weeks we teach and guide groups of around 30 women with various levels of coding experience in CSS/HTML, Python, or Ruby. These courses are a mixture of in-person classes and self-learning, at the same time the ladies involved work in teams of 2-4 people to build a project of their own interest.&lt;/p&gt;
&lt;p&gt;&lt;img alt="python1" src="http://rse.shef.ac.uk/images/CF_python3.jpg"&gt;&lt;/p&gt;
&lt;p&gt;The idea behind these workshops is rather simple: train people and provide them with practical use of the skills they are learning. Having as a final objective to develop a fully deployed RESTful app. But the whole CF:girls thing goes way beyond that. Over those 8 weeks the girls form a strong, motivating, and supportive community, in which they can acquire new skills, meet like-minded people, learn from other women working in STEM areas, and even attend external women in tech events!&lt;/p&gt;
&lt;p&gt;&lt;img alt="python1" src="http://rse.shef.ac.uk/images/CF_python2.jpg"&gt;&lt;/p&gt;
&lt;p&gt;I find rather interesting the mixture of apps and projects pursued, as well as the high quality of the presented final products. But beyond that, I find this to be an excellent opportunity to give back to the amazing community that has adopted and welcome me as a professional in a STEM area. Thus I can say for sure I will be getting involved in more Code First events/workshops.&lt;/p&gt;&lt;/div&gt;</description><guid>http://rse.shef.ac.uk/blog/sheffield-code-firstgirls/</guid><pubDate>Thu, 18 May 2017 08:32:49 GMT</pubDate></item><item><title>Coffee and Cakes Event</title><link>http://rse.shef.ac.uk/blog/coffee-and-cakes-event-2nd/</link><dc:creator>Mozhgan Kabiri Chimeh</dc:creator><description>&lt;div&gt;&lt;p&gt;RSE Sheffield is hosting another coffee and cakes event on &lt;strong&gt;May 31st at 14:00 in the Ada Lovelace room&lt;/strong&gt; on 1st floor of the Computer Science Department (Regents Court East). Attendance is free, but you need to register via &lt;a href="https://goo.gl/forms/L2dRQNvSUvkIbtSm2"&gt;this link&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Take the opportunity to come and have an informal chat about research software.&lt;/p&gt;
&lt;p&gt;This event is a community event for anyone, not just computer science or members of the RSE team. If you work on software development are an RSE or simply want to talk about some aspect of software or software in teaching then come along.&lt;/p&gt;&lt;/div&gt;</description><guid>http://rse.shef.ac.uk/blog/coffee-and-cakes-event-2nd/</guid><pubDate>Wed, 17 May 2017 11:12:12 GMT</pubDate></item><item><title>Building Linux GPU Code with NSIGHT in Windows</title><link>http://rse.shef.ac.uk/blog/building-linux-gpu-code-with-nsight-in-windows/</link><dc:creator>Paul Richmond</dc:creator><description>&lt;div&gt;&lt;p&gt;Why would you possibly want to build and execute CUDA GPU applications within NSight Eclipse for Linux within Microsoft Windows? Well if you use windows as your main OS there are plenty of reasons but the most obvious is that you may be developing cross platform code and want to build and test it without dual booting. If you are thinking about virtual machines then forget about it. Most (except some very expensive enterprise options) do not have the ability to access a GPU device (e.g GPU pass-through) from within a virtual machine. &lt;/p&gt;
&lt;p&gt;The purpose of this post is to describe how to install the necessary tools to permit local GPU development inside the Linux NSight IDE from within Windows. The advantages of which are not only cross platform development but also the ability to locally develop in powerful Linux IDE with remote execution and graphical debugging. This is particularly helpful if you want to execute or debug your code on a HPC system (like Sheffield's ShARC system) from Windows. The post focuses on the use of the new Windows 10 Linux subsystem, however you could use the approach to install CUDA tools on a lightweight Linux virtual machine. The concept is the same either way. i.e. build and debug locally execute remotely.&lt;/p&gt;
&lt;h3&gt;Configuring the Linux Windows Subsystem for CUDA compilation&lt;/h3&gt;
&lt;p&gt;The Windows 10 subsystem for Linux is available in the anniversary update. You can install it from the "Turn on or off windows features" dialogue. It is listed under "Windows subsystem for Linux (beta)". This alone is not enough to build our GPU applications as we will need to install CUDA. A normal CUDA install will require a local GPU and the installation of a CUDA compatible graphics driver. Fire up the Windows Bash Shell (or a Linux virtual machine). You can then use the following commands to install the CUDA toolkit without installing a graphics driver. This will install the core NVIDIA CUDA compiler (nvcc) and NSight. You can update the &lt;code&gt;CUDA_REPO_PKG&lt;/code&gt; variable to install a different CUDA version.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="x"&gt;sudo apt-get update&lt;/span&gt;
&lt;span class="x"&gt;CUDA_REPO_PKG=cuda-repo-ubuntu1404_8.0.44-1_amd64.deb&lt;/span&gt;
&lt;span class="x"&gt;wget http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1404/x86_64/&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;CUDA_REPO_PKG&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;
&lt;span class="x"&gt;sudo dpkg -i &lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;CUDA_REPO_PKG&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;
&lt;span class="x"&gt;sudo apt-get update&lt;/span&gt;
&lt;span class="x"&gt;sudo apt-get install -y --no-install-recommends cuda-core-8-0 cuda-cudart-dev-8-0 nsight&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;You can now create a symbolic link to a generic CUDA install. This will permit the addition and fast swapping of different CUDA versions.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="x"&gt;sudo ln -s /usr/local/cuda-8.0 /usr/local/cuda &lt;/span&gt;
&lt;span class="x"&gt;export PATH=&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;PATH&lt;/span&gt;&lt;span class="x"&gt;:/usr/local/cuda/bin&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;Note: if you want the CUDA bin location to be persistently on the PATH (after you reboot the Bash shell) then you will need to add the &lt;code&gt;export PATH&lt;/code&gt; line to your .bashrc profile. Test that the install was successful by running nvcc.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;nvcc --version
&lt;/pre&gt;


&lt;p&gt;This should give you some information on the nvcc version. e.g. &lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;nvcc&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;NVIDIA&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;R&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="n"&gt;Cuda&lt;/span&gt; &lt;span class="n"&gt;compiler&lt;/span&gt; &lt;span class="n"&gt;driver&lt;/span&gt;
&lt;span class="n"&gt;Copyright&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="mi"&gt;2005&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;2016&lt;/span&gt; &lt;span class="n"&gt;NVIDIA&lt;/span&gt; &lt;span class="n"&gt;Corporation&lt;/span&gt;
&lt;span class="n"&gt;Built&lt;/span&gt; &lt;span class="n"&gt;on&lt;/span&gt; &lt;span class="n"&gt;Tue_Jan_10_13&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;22&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;03&lt;/span&gt;&lt;span class="n"&gt;_CST_2017&lt;/span&gt;
&lt;span class="n"&gt;Cuda&lt;/span&gt; &lt;span class="n"&gt;compilation&lt;/span&gt; &lt;span class="n"&gt;tools&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;release&lt;/span&gt; &lt;span class="mf"&gt;8.0&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;V8&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mf"&gt;0.61&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;The CUDA toolkit is now installed so you can build (but not execute) CUDA GPU programs using the Linux bash shell.&lt;/p&gt;
&lt;h3&gt;Graphical editing with Nsight IDE&lt;/h3&gt;
&lt;p&gt;To be able to run a graphical NSight IDE from within the Windows subsystem for Linux you will need to be running a X server within Windows. You can install the &lt;strong&gt;free&lt;/strong&gt; &lt;a href="https://sourceforge.net/projects/xming/"&gt;XMing&lt;/a&gt; application for this purpose. If you would rather use a Linux virtual machine then you can avoid this step as the virtual machine will most likely have an X server included. The advantage of the Windows subsystem approach is that it is very lightweight. From within your Bash terminal you will need to set the following environment variable.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;export DISPLAY=:0
&lt;/pre&gt;


&lt;p&gt;The display variable is an environment variable passed to graphical applications. In this case, the value of &lt;code&gt;:0&lt;/code&gt; it tells the application to use the first display on the local system (our XMing server in this case). If you want to make this environment variable change permanent then you should add it to your .bashrc profile. You can now run the NSight application from Bash.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;nsight
&lt;/pre&gt;


&lt;p&gt;Glorious isn't it. Within NSight we can create a new CUDA project which will compile using the local CUDA install. In order to remotely execute and debug you can use the "C++ Remote application" run configuration. This will require SSH access to a suitable Linux machine with a GPU and CUDA installed.&lt;/p&gt;
&lt;p&gt;Future blog posts will cover how remote execution and debugging can be achieved on the University of Sheffield ShARC system. ShARC has a typical of job based HPC system which encourages job submission rather than execution of code on worker nodes via SSH logins. &lt;/p&gt;
&lt;h3&gt;Summary of Bash Profile Changes&lt;/h3&gt;
&lt;p&gt;I added the following to my .bashrc profile (located in the home directory) to ensure that NSight could be launched straight after starting the Bash shell in Windows.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;#&lt;/span&gt;&lt;span class="x"&gt; add cuda bin dir to path&lt;/span&gt;
&lt;span class="x"&gt;export PATH=&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;PATH&lt;/span&gt;&lt;span class="x"&gt;:/usr/local/cuda/bin&lt;/span&gt;

&lt;span class="err"&gt;#&lt;/span&gt;&lt;span class="x"&gt; export the display environment variable&lt;/span&gt;
&lt;span class="x"&gt;export DISPLAY=:0&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</description><guid>http://rse.shef.ac.uk/blog/building-linux-gpu-code-with-nsight-in-windows/</guid><pubDate>Mon, 08 May 2017 16:03:00 GMT</pubDate></item><item><title>Spark and Scala on Sheffield HPC systems</title><link>http://rse.shef.ac.uk/blog/spark-scala-sheffield-hpc/</link><dc:creator>Mike Croucher</dc:creator><description>&lt;div&gt;&lt;p&gt;As part of our support for a Large scale machine learning MSc course in Computer Science, the Sheffield RSE group put together a tutorial for how to use &lt;a href="http://spark.apache.org/"&gt;Spark&lt;/a&gt; and Scala on &lt;a href="http://docs.hpc.shef.ac.uk/en/latest/"&gt;Sheffields HPC systems&lt;/a&gt;.
We are sharing with the rest of the community in case its useful to you &lt;a href="https://github.com/mikecroucher/Intro_to_HPC/blob/gh-pages/README.md"&gt;https://github.com/mikecroucher/Intro_to_HPC/blob/gh-pages/README.md&lt;/a&gt; &lt;/p&gt;
&lt;p&gt;Its for people whove never used a HPC system before. By the time theyve finished, they are able to submit their own Spark jobs to the HPC cluster.
If anyone is interested in us re-running this as a workshop (it takes around 2 hours) let us know.&lt;/p&gt;
&lt;p&gt;Some notes on our current implementation of Spark on HPC:-&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;We are currently restricted to jobs that run on one node. This is because Sheffields HPC clusters are not traditional Hadoop/Spark clusters and so some level of integration is required between Sun Grid Engine and Spark. We've only managed to get as far as implementing this across single nodes at the moment.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;One way weve fudged this is to make sure that we provide our students with access to nodes with a LOT of memory  768 GB per node in fact, 12 times as much as you get on a normal node on ShARC or Iceberg. We are experimenting with allowing others access to our kit via a contribution based model. See &lt;a href="http://rse.shef.ac.uk/resources/hpc/premium-hpc"&gt;http://rse.shef.ac.uk/resources/hpc/premium-hpc/&lt;/a&gt; for details.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;/div&gt;</description><guid>http://rse.shef.ac.uk/blog/spark-scala-sheffield-hpc/</guid><pubDate>Mon, 08 May 2017 11:17:05 GMT</pubDate></item><item><title>Job validation with Grid Engine: false negatives</title><link>http://rse.shef.ac.uk/blog/sge-job-validation-2/</link><dc:creator>Will Furnass</dc:creator><description>&lt;div&gt;&lt;p&gt;In &lt;a href="http://rse.shef.ac.uk/blog/sge-job-validation"&gt;a previous post&lt;/a&gt;, 
I noted that if you're not sure if a Sun Grid Engine (SGE) job can ever run on an &lt;a href="https://en.wikipedia.org/wiki/Supercomputer"&gt;HPC cluster&lt;/a&gt;
you can perform 'dry-run' job validation:
by passing &lt;code&gt;-w v&lt;/code&gt; as arguments to &lt;code&gt;qrsh&lt;/code&gt;/&lt;code&gt;qrshx&lt;/code&gt;/&lt;code&gt;qsh&lt;/code&gt;/&lt;code&gt;qalter&lt;/code&gt; you can ask the SGE scheduler software 
if your job could ever run if the cluster were entirely empty of other jobs.&lt;/p&gt;
&lt;p&gt;For example:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;    qsub -pe smp 2 -l rmem=10000G -w v myjob.sge
&lt;/pre&gt;


&lt;p&gt;would most likely tell you that your job could not be run in any of the cluster's job queues 
(due to the size of the resource request).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;But beware:&lt;/strong&gt; 
as mentioned in my earlier post 
this his job validation mechanism sometimes results in &lt;em&gt;false negatives&lt;/em&gt; i.e. you are told that a job cannot run even though though in reality it can.&lt;br&gt;
This is something that the HPC sysadmin team at the University of Leeds alerted us to.&lt;/p&gt;
&lt;p&gt;Here's an example of a false positive (using our &lt;a href="https://docs.hpc.shef.ac.uk/en/latest/sharc/"&gt;ShARC&lt;/a&gt; cluster.&lt;br&gt;
If you ask for a single-core interactive session with access to four GPUs then dry-run validation fails:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;    [te1st@sharc-login1 ~]$ qrsh -l gpu=4 -w v
    ...
    verification: no suitable queues
&lt;/pre&gt;


&lt;p&gt;yet (without validation) the resource request can be satisfied:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;    [te1st@sharc-login1 ~]$ qrsh -l gpu=4 
    [te1st@sharc-node100 ~]$   # works!
&lt;/pre&gt;


&lt;p&gt;The &lt;strong&gt;reason for this&lt;/strong&gt; appears to be that the validation is performed 
without running any &lt;a href="http://gridscheduler.sourceforge.net/htmlman/htmlman1/jsv.html"&gt;Job Submission Verifier&lt;/a&gt; (JSV) scripts.
These scripts are run (typically on the SGE master machine) on every submitted job to 
centrally modify or reject job requests post-submission.&lt;/p&gt;
&lt;p&gt;On ShARC the main JSV script changes a job's &lt;a href="http://gridscheduler.sourceforge.net/htmlman/htmlman5/project.html?pathrev=V62u5_TAG"&gt;Project&lt;/a&gt; 
from a generic one 
to &lt;code&gt;gpu&lt;/code&gt; 
if &lt;code&gt;x &amp;gt; 0&lt;/code&gt; GPUs have been requested using &lt;code&gt;-l gpu=x&lt;/code&gt;.
The job can then be assigned to (GPU-equipped) nodes associated with that project.
So, if the JSV is not run before job validation (using &lt;code&gt;-w v&lt;/code&gt;) then 
validation of jobs that request GPUs will fail as 
no nodes (more accurately &lt;em&gt;queue instances&lt;/em&gt;) will be found that can satisfy the resource request 
given the (default) project of jobs.  &lt;/p&gt;
&lt;p&gt;The workaround here is to explicitly request a Project (using e.g. &lt;code&gt;-P gpu&lt;/code&gt;) 
when trying to validate a job using &lt;code&gt;-w v&lt;/code&gt; 
i.e. partly duplicate the logic in the (bypassed) JSV,
but this requires that you know have read and understood the JSV.&lt;br&gt;
This is something that users may not want to do and adds complexity, 
when the whole point of investigating job validation in the first place was to 
find a simple way by which users could check if if their jobs could run on a given SGE cluster.&lt;/p&gt;
&lt;p&gt;In summary, SGE's job validation mechanism is not a fool-proof option for users as 
it does not take into consideration changes made to a job by Job Submission Verifier scripts post-submission.&lt;/p&gt;&lt;/div&gt;</description><guid>http://rse.shef.ac.uk/blog/sge-job-validation-2/</guid><pubDate>Wed, 19 Apr 2017 10:15:00 GMT</pubDate></item><item><title>Introduction to Modern Fortran</title><link>http://rse.shef.ac.uk/blog/ModernFortran2017/</link><dc:creator>Mike Croucher</dc:creator><description>&lt;div&gt;&lt;p&gt;In February, the Research Software Engineering group hosted an ‘Introduction to Modern Fortran Course’ taught by EPSRC Research Software Engineering Fellow, &lt;a href="http://www.walkingrandomly.com/?p=6006"&gt;Ian Bush&lt;/a&gt;. The course material is available at &lt;a href="https://www.oerc.ox.ac.uk/introduction-modern-fortran-course-materials"&gt;https://www.oerc.ox.ac.uk/introduction-modern-fortran-course-materials&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;During the day, Ian recommended a bunch of books (below)&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://rse.shef.ac.uk/images/fortran_books.jpg"&gt;&lt;/p&gt;
&lt;p&gt;We’ve been working with the University library and I’m happy to announce that all of these are now available to borrow. Search for them using the &lt;a href="https://find.shef.ac.uk/primo_library/libweb/action/search.do"&gt;University catalogue&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;</description><guid>http://rse.shef.ac.uk/blog/ModernFortran2017/</guid><pubDate>Wed, 19 Apr 2017 10:12:51 GMT</pubDate></item><item><title>Determining MPI placement on the HPC clusters</title><link>http://rse.shef.ac.uk/blog/mpi_placement/</link><dc:creator>Mike Croucher</dc:creator><description>&lt;div&gt;&lt;p&gt;Say you request a 16 slot MPI job on ShARC with 3GB per-process using a submission script like the one below:&lt;/p&gt;
&lt;table class="codehilitetable"&gt;&lt;tr&gt;&lt;td class="linenos"&gt;&lt;div class="linenodiv"&gt;&lt;pre&gt; 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="ch"&gt;#!/bin/bash&lt;/span&gt;
&lt;span class="c1"&gt;#Tell the scheduler that maximum runtime is 1 hour&lt;/span&gt;
&lt;span class="c1"&gt;#$ -l h_rt=1:00:00&lt;/span&gt;
&lt;span class="c1"&gt;#Request 16 slots&lt;/span&gt;
&lt;span class="c1"&gt;#$ -pe mpi 16&lt;/span&gt;
&lt;span class="c1"&gt;#Request 3 Gigabytes per slot&lt;/span&gt;
&lt;span class="c1"&gt;#$ -l rmem=3G&lt;/span&gt;

&lt;span class="c1"&gt;#Load gcc 4.9.4 and OpenMPI 2.0.1&lt;/span&gt;
module load dev/gcc/4.9.4
module load mpi/openmpi/2.0.1/gcc-4.9.4

mpirun  ./MPI_hello_world
&lt;/pre&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;

&lt;p&gt;The scheduler is free to decide where on the system your 16 slots get placed. You may have all 16 slots running on one node, one slot per node for 16 nodes or anything in between. The exact placement of your jobs may affect runtime.&lt;/p&gt;
&lt;p&gt;We can find out where the scheculer placed your MPI processes using the &lt;code&gt;$PE_HOSTFILE&lt;/code&gt; environment variable. When your job starts running, this points to a file that contains placement information. We make use of it in a submission script as follows&lt;/p&gt;
&lt;table class="codehilitetable"&gt;&lt;tr&gt;&lt;td class="linenos"&gt;&lt;div class="linenodiv"&gt;&lt;pre&gt; 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="ch"&gt;#!/bin/bash&lt;/span&gt;
&lt;span class="c1"&gt;#Tell the scheduler that maximum runtime is 1 hour&lt;/span&gt;
&lt;span class="c1"&gt;#$ -l h_rt=1:00:00&lt;/span&gt;
&lt;span class="c1"&gt;#Request 16 slots&lt;/span&gt;
&lt;span class="c1"&gt;#$ -pe mpi 16&lt;/span&gt;
&lt;span class="c1"&gt;#Request 3 Gigabytes per slot&lt;/span&gt;
&lt;span class="c1"&gt;#$ -l rmem=3G&lt;/span&gt;

&lt;span class="c1"&gt;#Load gcc 4.9.4 and OpenMPI 2.0.1&lt;/span&gt;
module load dev/gcc/4.9.4
module load mpi/openmpi/2.0.1/gcc-4.9.4

&lt;span class="c1"&gt;#Put placement information into node_info.txt&lt;/span&gt;
cat &lt;span class="nv"&gt;$PE_HOSTFILE&lt;/span&gt;  &amp;gt; node_info.txt

mpirun  ./MPI_hello_world
&lt;/pre&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;

&lt;p&gt;You'll now get a file called &lt;code&gt;node_info.txt&lt;/code&gt; that contains information about which nodes your MPI slots were placed. For example&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;sharc-node031.shef.ac.uk 1 shortint.q@sharc-node031.shef.ac.uk UNDEFINED
sharc-node069.shef.ac.uk 1 shortint.q@sharc-node069.shef.ac.uk UNDEFINED
sharc-node112.shef.ac.uk 1 shortint.q@sharc-node112.shef.ac.uk UNDEFINED
sharc-node108.shef.ac.uk 1 shortint.q@sharc-node108.shef.ac.uk UNDEFINED
sharc-node081.shef.ac.uk 1 shortint.q@sharc-node081.shef.ac.uk UNDEFINED
sharc-node090.shef.ac.uk 2 shortint.q@sharc-node090.shef.ac.uk UNDEFINED
sharc-node080.shef.ac.uk 2 shortint.q@sharc-node080.shef.ac.uk UNDEFINED
sharc-node050.shef.ac.uk 3 shortint.q@sharc-node050.shef.ac.uk UNDEFINED
sharc-node059.shef.ac.uk 4 shortint.q@sharc-node059.shef.ac.uk UNDEFINED
&lt;/pre&gt;


&lt;p&gt;In the above example, 4 slots were placed on node059, 3 slots on node 50, 2 slots on nodes 080 and 090 and one slot on the other listed nodes. &lt;/p&gt;&lt;/div&gt;</description><guid>http://rse.shef.ac.uk/blog/mpi_placement/</guid><pubDate>Sat, 01 Apr 2017 16:03:00 GMT</pubDate></item><item><title>Job validation with Grid Engine</title><link>http://rse.shef.ac.uk/blog/sge-job-validation/</link><dc:creator>Will Furnass</dc:creator><description>&lt;div&gt;&lt;p&gt;(&lt;strong&gt;Edit&lt;/strong&gt;: caveats are listed in a &lt;a href="http://rse.shef.ac.uk/blog/sge-job-validation-2"&gt;more recent post&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Computer cluster job scheduling software is fantastic at managing resources 
and permitting many jobs to run efficiently and simultaneously.&lt;br&gt;
However, schedulers aren't always great at giving end-users feedback 
when things go wrong.  &lt;/p&gt;
&lt;p&gt;For example, on our ShARC cluster, which runs the (Son of) Grid Engine (SGE) scheduler, 
if you request a longer run-time than is permitted by any of the cluster's job queue configurations 
then your job will sit there queueing indefinitely until you or someone else deletes it.&lt;br&gt;
For example, let's use &lt;a href="http://docs.hpc.shef.ac.uk/en/latest/hpc/scheduler/sge.html#running-batch-jobs-on-iceberg"&gt;qsub&lt;/a&gt; 
to submit a job where we ask for 1000 hours of run time and 4 GiB of RAM:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;will@mysofa ~&lt;span class="o"&gt;]&lt;/span&gt;$ ssh sharc
...
&lt;span class="o"&gt;[&lt;/span&gt;te1st@sharc-login1 ~&lt;span class="o"&gt;]&lt;/span&gt;$ qsub -l &lt;span class="nv"&gt;h_rt&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;1000:00:00 -l &lt;span class="nv"&gt;rmem&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;4G -m bea -M w.furnass@sheffield.ac.uk -N longtask myjobscript.sge

Your job &lt;span class="m"&gt;236268&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"STDIN"&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; has been submitted
&lt;span class="o"&gt;[&lt;/span&gt;te1st@sharc-login1 ~&lt;span class="o"&gt;]&lt;/span&gt;$ qstat -u &lt;span class="nv"&gt;$USER&lt;/span&gt;
job-ID  prior   name       user         state submit/start at     queue                          slots ja-task-ID 
-----------------------------------------------------------------------------------------------------------------
 &lt;span class="m"&gt;217834&lt;/span&gt; 0.00000 longtask   te1st        qw    03/20/2017 10:48:39                                    &lt;span class="m"&gt;1&lt;/span&gt;        
&lt;/pre&gt;


&lt;p&gt;Job 217834 will now sit queuing forever.&lt;br&gt;
Not only will you not be told why, 
you won't be given &lt;em&gt;any&lt;/em&gt; notification that the job will not run.&lt;/p&gt;
&lt;p&gt;In situations like this it can be useful to ask the scheduler to validate a job.&lt;br&gt;
One way of doing this is to run '&lt;code&gt;qalter -w v &amp;lt;myjobid&amp;gt;&lt;/code&gt;' after job submission 
if say you think that a job has now been queueing for longer 
than previously-submitted jobs of a similar nature:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;[te1st@sharc-login1 ~]$ qalter -w v 217834
Job 217834 (-l h_rt=3600000) cannot run in queue "flybrain.q" because of cluster queue
Job 217834 (-l h_rt=3600000) cannot run in queue "gpu.q" because of cluster queue
Job 217834 (-l h_rt=3600000) cannot run in queue "gen2reg.q" because of cluster queue
Job 217834 (-l h_rt=3600000) cannot run in queue "rse.q" because of cluster queue
Job 217834 (-l h_rt=3600000) cannot run in queue "gpu-vis.q" because of cluster queue
Job 217834 (-l h_rt=3600000) cannot run in queue "insigneo-polaris.q" because of cluster queue
Job 217834 (-l h_rt=3600000) cannot run in queue "interactive.q" because of cluster queue
Job 217834 (-l h_rt=3600000) cannot run in queue "shortint.q" because of cluster queue
Job 217834 (-l h_rt=3600000) cannot run in queue "all.q" because of cluster queue
Job 217834 (-l h_rt=3600000) cannot run in queue "evolgen.q" because of cluster queue
Job 217834 (-l h_rt=3600000) cannot run in queue "rse-training.q" because of cluster queue
Job 217834 (-l h_rt=3600000) cannot run in queue "cstest.q" because of cluster queue
verification: no suitable queues
&lt;/pre&gt;


&lt;p&gt;What this '&lt;code&gt;qalter -w v &amp;lt;myjobid&amp;gt;&lt;/code&gt;' command does is check to see whether the job could run 
in any of the job queues on the cluster 
if the cluster were free of other jobs. &lt;/p&gt;
&lt;p&gt;The last line of output is key: 
our job will never be run given the current cluster configuration.&lt;br&gt;
Looking above that, we can see that it cannot run in any of the general-purpose job queues 
(such as &lt;code&gt;all.q&lt;/code&gt;) and 
there is specific mention of our 1000 hour (3600000s) run-time resource request.&lt;br&gt;
We can therefore deduce that our run-time resource request wasn't satisfiable.&lt;/p&gt;
&lt;h3&gt;Modifying a resource request post-submission&lt;/h3&gt;
&lt;p&gt;Once we know that our job can't run we could then delete our job...&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;te1st@sharc-login1 ~&lt;span class="o"&gt;]&lt;/span&gt;$ qdel &lt;span class="m"&gt;217834&lt;/span&gt; 
te1st has deleted job &lt;span class="m"&gt;217834&lt;/span&gt; 
&lt;/pre&gt;


&lt;p&gt;...then consult the cluster's documentation to discover the maximum possible run-time and resubmit using more sensible resource requests.  &lt;/p&gt;
&lt;p&gt;Alternatively we can use &lt;strong&gt;qalter&lt;/strong&gt; to modify the resource requests associated with a queueing job:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;qalter -l &lt;span class="nv"&gt;h_rt&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;96:00:00 -l &lt;span class="nv"&gt;rmem&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;4G &lt;span class="m"&gt;217834&lt;/span&gt; 
&lt;/pre&gt;


&lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;: using &lt;code&gt;qalter&lt;/code&gt; in this fashion will change &lt;strong&gt;all&lt;/strong&gt; resource requests for the job so here we need to re-specify the &lt;code&gt;rmem&lt;/code&gt; request.&lt;/p&gt;
&lt;h3&gt;Job validation at submission time&lt;/h3&gt;
&lt;p&gt;You can also perform the same type of job validation &lt;strong&gt;at job submission time&lt;/strong&gt; using &lt;code&gt;-w v&lt;/code&gt; e.g.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;qsub -w v -l 1000:00:00 -l &lt;span class="nv"&gt;rmem&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;4G myjobscript.sge
&lt;/pre&gt;


&lt;p&gt;This won't actually submit your job; it just performs validation.&lt;/p&gt;
&lt;h3&gt;Why is validation not performed by default?&lt;/h3&gt;
&lt;p&gt;You may ask why such validation is not enabled by default for all jobs; 
one reason for this is that it is believed it would place undue burden on the scheduler.&lt;/p&gt;
&lt;p&gt;Another is that sometimes a validation attempt results in a false negative that can be difficult to automatically identify
(&lt;strong&gt;edit&lt;/strong&gt;: see this &lt;a href="http://rse.shef.ac.uk/blog/sge-job-validation-2"&gt;more recent post&lt;/a&gt; for details).&lt;/p&gt;
&lt;h3&gt;Other types of resources&lt;/h3&gt;
&lt;p&gt;If you repeat the experiment outlined above but 
instead of requesting 1000 hours of runtime 
you ask for 100 GPUs, 9999GB of RAM or 10000 cores 
you'll observe the same behaviour: jobs that make requests unsatisfiable under the current cluster configuration can be submitted but will never run.&lt;/p&gt;
&lt;p&gt;Again, job validation can help here but depending on the type of resource the validation error messages can be more or less cryptic.&lt;br&gt;
For example, if you try to validate a 100000-'slot' (core) MPI job using &lt;code&gt;-w v&lt;/code&gt; you get the following:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;qsub -pe mpi 100000 -w v somejob.sge
...
Job 311838 cannot run in PE "mpi" because it only offers 0 slots
&lt;/pre&gt;


&lt;p&gt;This is rather misleading but the mention of 'slots' should prompt you to check the number of cores you've requested is sensible.&lt;/p&gt;
&lt;h3&gt;'Poke' validation: consider the current cluster load&lt;/h3&gt;
&lt;p&gt;Another type of validation is &lt;em&gt;poke&lt;/em&gt; validation, 
which checks if a job could be run under the current cluster &lt;em&gt;load&lt;/em&gt; 
i.e. with many of the cluster's resources already in use.&lt;br&gt;
See &lt;code&gt;man qsub&lt;/code&gt; and search for &lt;code&gt;-w&lt;/code&gt; 
for more information on the different types of validation.&lt;/p&gt;&lt;/div&gt;</description><guid>http://rse.shef.ac.uk/blog/sge-job-validation/</guid><pubDate>Mon, 20 Mar 2017 10:44:00 GMT</pubDate></item><item><title>Computational Mathematics with Jupyter workshop</title><link>http://rse.shef.ac.uk/blog/icms-2017/</link><dc:creator>Will Furnass</dc:creator><description>&lt;div&gt;&lt;p&gt;Back in mid-January three members of the University of Sheffield's Research Software Engineering Team
(me, &lt;a class="reference external" href="http://rse.shef.ac.uk/contact/"&gt;Mike Croucher&lt;/a&gt; and &lt;a class="reference external" href="http://rse.shef.ac.uk/blog/tania_allard"&gt;Tania Allard&lt;/a&gt;)
spent a week at a &lt;a class="reference external" href="http://opendreamkit.org/meetings/2017-01-16-ICMS/"&gt;Computational Mathematics with Jupyter workshop&lt;/a&gt;, hosted at Edinburgh's &lt;a class="reference external" href="http://www.icms.org.uk/"&gt;International Centre for Mathematical Sciences&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This brought together the many members of the consortium working on the &lt;a class="reference external" href="http://opendreamkit.org/"&gt;OpenDreamKit&lt;/a&gt; Horizon 2020 European Research Infrastructure project.
The overall aim of the project is broad (to further the open-source computational mathematics ecosystem)
so it was unsurprising that the collective experience of the attendees was too.
The attendees generally fell into one of the following four camps:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Researchers interested in solving &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Group_theory"&gt;Group Theory&lt;/a&gt; and &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Semigroup"&gt;Semigroup&lt;/a&gt; problems using the &lt;a class="reference external" href="https://www.gap-system.org/"&gt;GAP&lt;/a&gt; software,
some of which were involved with developing a &lt;a class="reference external" href="http://jupyter.readthedocs.io/en/latest/projects/kernels.html"&gt;Jupyter kernel&lt;/a&gt; for GAP;&lt;/li&gt;
&lt;li&gt;Others interested in the &lt;a class="reference external" href="http://www.sagemath.org/"&gt;SageMath&lt;/a&gt; computational mathematics ecosystem
(which is particularly strong for computational algebra) and
working on a Jupyter kernel for it;&lt;/li&gt;
&lt;li&gt;Research Software Engineers working on interactive widgets, visualisation tools and workflow tools for &lt;a class="reference external" href="http://jupyter.readthedocs.io/"&gt;Jupyter&lt;/a&gt;;&lt;/li&gt;
&lt;li&gt;People with experience/interest in using computational mathematics tools for teaching purposes.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="figure align-center"&gt;
&lt;img alt="The attendees of the workshop" src="http://rse.shef.ac.uk/images/icms-2017-attendees.jpg"&gt;
&lt;p class="caption"&gt;The attendees of the workshop.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The structure was different from conferences I'd attended previously:
for each of the five days we listened and debated presentations in the morning then
busied ourselves with &lt;a class="reference external" href="https://www.software.ac.uk/blog/2017-02-23-computational-mathematics-jupyter-sprint"&gt;code sprints&lt;/a&gt; in the afternoons.&lt;/p&gt;
&lt;div class="section" id="correctness-sustainability-and-human-fallibility"&gt;
&lt;h2&gt;Correctness, sustainability and human fallibility&lt;/h2&gt;
&lt;p&gt;Our own Mike Croucher kicked things off by asking
&lt;a class="reference external" href="http://mikecroucher.github.io/MLPM_talk/"&gt;Is your research software correct?&lt;/a&gt;
in which he presented &lt;strong&gt;Croucher's Law&lt;/strong&gt;:&lt;/p&gt;
&lt;blockquote&gt;
I can be an idiot and &lt;strong&gt;will&lt;/strong&gt; make mistakes.&lt;/blockquote&gt;
&lt;p&gt;with the corollary that&lt;/p&gt;
&lt;blockquote&gt;
You are no different!&lt;/blockquote&gt;
&lt;p&gt;He argued, convincingly, that in our research we therefore need to put in place safeguards
to lessen the chance and impact of mistakes, and
proposed the following as partial solutions:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Automate (aka learn to program)&lt;/li&gt;
&lt;li&gt;Write code in a (very) high-level language&lt;/li&gt;
&lt;li&gt;Get some training&lt;/li&gt;
&lt;li&gt;Use version control&lt;/li&gt;
&lt;li&gt;Get a code buddy (Maybe an &lt;a class="reference external" href="http://rse.shef.ac.uk/contact/"&gt;RSE&lt;/a&gt;!)&lt;/li&gt;
&lt;li&gt;Share your code and data openly&lt;/li&gt;
&lt;li&gt;Use literate computing technologies&lt;/li&gt;
&lt;li&gt;Write tests&lt;/li&gt;
&lt;li&gt;Cite code&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a class="reference external" href="https://www.software.ac.uk/raniere-silva"&gt;Raniere Silva&lt;/a&gt; from the &lt;a class="reference external" href="https://www.software.ac.uk/"&gt;Software Sustainability Institute&lt;/a&gt; followed on with a complementary talk on how to make computational mathematics software more sustainable.  He commented that odd numerical bugs can easily creep in over time (e.g. differing floating point behaviour between Python 2 and 3) but that we can maintain confidence in software using version control, continuous integration, good documentation, tutorials, knowledge bases, instant messaging and by developing communities around the software we value.&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://blogs.cs.st-andrews.ac.uk/alexk/"&gt;Alexander Konovalov&lt;/a&gt; then talked about a particular case of making research software more sustainable and portable: he's been using &lt;a class="reference external" href="http://www.docker.com/"&gt;Docker&lt;/a&gt; containers to run &lt;a class="reference external" href="https://www.gap-system.org/"&gt;GAP&lt;/a&gt;.  This lead into a discussion on whether Docker is a sensible solution for archiving/reproducing workflows: will it be around in ten years' time?  Those interested in that particular issue might benefit from attending the forthcoming &lt;a class="reference external" href="https://www.software.ac.uk/"&gt;Software Sustainability Institute&lt;/a&gt; workshop on &lt;a class="reference external" href="https://www.software.ac.uk/c4rr"&gt;Docker Containers for Reproducible Research&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="jupyter-what-is-it-and-how-can-we-diff-merge-test-notebooks"&gt;
&lt;h2&gt;Jupyter: what is it and how can we diff/merge/test Notebooks?&lt;/h2&gt;
&lt;p&gt;We were then given what was pitched as a &lt;strong&gt;'general introduction' to Jupyter&lt;/strong&gt;
but ended up covering much more ground than anticipated,
largely due to the speaker being &lt;a class="reference external" href="https://twitter.com/takluyver"&gt;Thomas Kluyver&lt;/a&gt;, one of the core IPython developers
(who happens to have gained his PhD from the University of Sheffield).
Thomas talked about the most significant features
(literate programming environments;
the power and versatility of using the browser as a &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop"&gt;REPL&lt;/a&gt;;
Jupyter's client-server architecture)
but also touched upon
&lt;strong&gt;various tools and platforms that have built on Jupyter&lt;/strong&gt; including:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://jupyterhub.readthedocs.io/en/latest/"&gt;JupyterHub&lt;/a&gt;: a multi-user hub which "spawns, manages, and proxies multiple instances of the single-user Jupyter Notebook server".  One of the University of Sheffield's deliverables for the OpenDreamKit project is to get this running on our own computer clusters so users dictate what resources (e.g. cores, memory, GPUs) they want when they start a single-user Notebook session;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/jupyter/tmpnb"&gt;tmpnb&lt;/a&gt;: a JupyterHub-like system for launching temporary single-user Notebook sessions in the cloud (which are each backed by a Docker container).  tmpnb powers &lt;a class="reference external" href="https://try.jupyter.org/"&gt;https://try.jupyter.org/&lt;/a&gt; (hosted by RackSpace), which allows people to briefly test out Jupyter without installing anything locally;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://mybinder.org/"&gt;binder&lt;/a&gt;: a tool for turning a GitHub repository into a collection of interactive Notebooks, configuring the required environment/dependencies using a Dockerfile, Python requirements.txt file or Conda environment file;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://nbgrader.readthedocs.io/en/stable/"&gt;nbgrader&lt;/a&gt;: a tool for distributing coding and/or free text Notebook-based assignments then automatically or manually grading them.  This can integrate with JupyterHub;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://nbconvert.readthedocs.io/en/latest/"&gt;nbconvert&lt;/a&gt;: convert a Notebook to HTML/Markdown/PDF/scripts or a custom format (using a &lt;a class="reference external" href="http://jinja.pocoo.org/"&gt;Jinja2&lt;/a&gt; template).  It is used by &lt;a class="reference external" href="http://rse.shef.ac.uk/blog/icms-2017/nbviewer.jupyter.org"&gt;nbviewer.jupyter.org&lt;/a&gt; to create online static HTML views of Notebooks.  nbconvert is also used by GitHub for rendering Notebooks;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/takluyver/nbparameterise"&gt;nbparameterise&lt;/a&gt;:  Often you want design Notebooks to demonstrate/explore the impact of a small number of key variables.  This project of Thomas's allows such variables to be set in the first code cell then the entire Notebook can be run non-interactively and rendered to HTML;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/jupyterlab/jupyterlab"&gt;jupyterlab&lt;/a&gt;: This will be the next iteration of Jupyter's UI: rather than exclusively displaying a terminal, Notebook or file editor in the Jupyter interface, instead a multi-tab and multi-pane interface allows you to view and interact with several of these things at once.  It will therefore look and feel a bit more like Spyder/R Studio/MATLAB but this is no bad thing as all of those make good use of screen real estate provided by the wide monitors we all have these days.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="figure align-center"&gt;
&lt;img alt="JupyterLab: the future of the Jupyter interface" src="http://rse.shef.ac.uk/images/jupyterlab.png"&gt;
&lt;p class="caption"&gt;JupyterLab: the future of the Jupyter interface.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Given the enormity of the Jupyter ecosystem and how quickly it has grown
it was great to hear from a core developer which related projects he thinks are the most significant and interesting!&lt;/p&gt;
&lt;p&gt;Next up, Vidar Fauske gave &lt;a class="reference external" href="http://opendreamkit.org/meetings/2017-01-16-ICMS/talks/nbdime.pdf"&gt;this talk&lt;/a&gt; on &lt;a class="reference external" href="https://nbdime.readthedocs.io/en/latest/"&gt;nbdime&lt;/a&gt;, a new tool for &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Merge_(version_control)"&gt;merging&lt;/a&gt; and &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Diff_utility"&gt;diffing&lt;/a&gt; Jupyter Notebooks.
The backstory is that for some time we've been recommending Jupyter to those wanting to start using Python or R in their research and we've also been telling everyone to use version control but the diffing and merging tools typically used with version control systems don't work well with Notebooks as they&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Operate on lines without consideration of whether a file has a nested structure (JSON in the case of Notebooks);&lt;/li&gt;
&lt;li&gt;Base64-encoded binary objects in Notebooks are naively treated in just the same way as text;&lt;/li&gt;
&lt;li&gt;No logic for omitting certain entities (execution counters; cell outputs) from version control (although the wonderful &lt;a class="reference external" href="https://github.com/kynan/nbstripout"&gt;nbstripout&lt;/a&gt; can handle both of these cases when triggered by a &lt;a class="reference external" href="https://git-scm.com/book/en/v2/Customizing-Git-Git-Hooks"&gt;git hook&lt;/a&gt;).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Ultimately visualising the differences between two Notebooks and merging Notebooks in sensible, useful ways really requires that the tools that perform these functions have some understanding of the structure and purpose of Notebooks: &lt;strong&gt;nbdime&lt;/strong&gt; has that awareness:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;The major unit for merging/diffing is the &lt;strong&gt;cell&lt;/strong&gt;, the line.&lt;/li&gt;
&lt;li&gt;Input cell merging is string merging whereas&lt;/li&gt;
&lt;li&gt;Cell outputs are treated as atomic: they match or they don't.&lt;/li&gt;
&lt;li&gt;Execution counts are sensibly ignored by default.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;nbdime provides a core library, plus command-line and browser interfaces for diffing and merging.&lt;/p&gt;
&lt;p&gt;Overall, I'm massively excited about nbdime for facilitating much slicker Notebook-based version controlled workflows and hope it sees widespread adoption and promotion by the likes of &lt;a class="reference external" href="https://software-carpentry.org/lessons/"&gt;Software Carpentry&lt;/a&gt;.&lt;/p&gt;
&lt;div class="figure align-center"&gt;
&lt;img alt="nbdime's nbdiff tool for viewing the differences between two Notebooks" src="http://rse.shef.ac.uk/images/nbdiff-example.png"&gt;
&lt;p class="caption"&gt;nbdime's nbdiff tool for viewing the differences between two Notebooks.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Hans Fangohr then introduced &lt;a class="reference external" href="https://github.com/computationalmodelling/nbval"&gt;nbval&lt;/a&gt;, a new tool for &lt;strong&gt;automating the valdation of Jupyter Notebooks&lt;/strong&gt;.  This could give researchers greater confidence in their workflows: &lt;strong&gt;does a demonstrative Notebook still give the same answers if re-run after making changes to the Notebook's environment (e.g. the package dependencies)?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;nbval, a &lt;a class="reference external" href="http://doc.pytest.org/en/latest/"&gt;pytest&lt;/a&gt; plug-in, works as follows: it creates a copy of a Notebook file, executes the copy in the current Python environment, saves the copy Notebook with its new cell outputs then compares the outputs of the two Notebooks.  There are some nice features to control the granularity of testing: flags can be set so certain cells are run but not tested; &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Regular_expression"&gt;regexes&lt;/a&gt; can be used to ignore oft-changing output strings (e.g. paths, timestamps, memory addresses).  Images and LaTeX can't be handled yet.&lt;/p&gt;
&lt;p&gt;Again, I'm exited about this new tool: being able to package both workflow documentation and regression/ acceptance tests as Notebooks is a great idea.  Note that at present both nbdime and nbval include mechanisms for comparing Notebooks but are presently separate projects.  It will be interesting to see if there's any convergence in future.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="interactive-widgets-in-notebooks"&gt;
&lt;h2&gt;Interactive widgets in Notebooks&lt;/h2&gt;
&lt;p&gt;We were treated to two talks on the &lt;a class="reference external" href="https://ipywidgets.readthedocs.io/en/latest/"&gt;ipywidgets&lt;/a&gt; package, which provides &lt;strong&gt;Python and Javascript-backed widgets for interacting with Notebooks&lt;/strong&gt; e.g. sliders for assessing the impact of model parameters on trends in embedded &lt;a class="reference external" href="http://matplotlib.org/"&gt;matplotlib&lt;/a&gt; plots.&lt;/p&gt;
&lt;p&gt;First, &lt;a class="reference external" href="https://github.com/jdemeyer"&gt;Jeroen Demeyer&lt;/a&gt; introduced us to the high-level &lt;tt class="docutils literal"&gt;interact&lt;/tt&gt; Python decorator function and &lt;tt class="docutils literal"&gt;interactive&lt;/tt&gt; class one can use to control function inputs using a HTML+Javascript widget.  He then went on to explain how one can manually reproduce the magic of these mechanisms: you instantiate some (typed) input widgets and output widgets, add them to an on-screen container then associate each input widget with a callback.&lt;/p&gt;
&lt;p&gt;Next, &lt;a class="reference external" href="http://www.proba.jussieu.fr/pageperso/corlay/"&gt;Sylvain Corlay&lt;/a&gt; talked about the ipywidgets ecosystem and the future direction of the project.  He mentioned several projects that have built on ipywidgets, all of which sound exciting but none of which I'd heard of before this!&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/bloomberg/bqplot"&gt;bqplot&lt;/a&gt;: a &lt;a class="reference external" href="http://matplotlib.org/"&gt;matplotlib&lt;/a&gt; alternative that supports the same API, uses custom ipywidgets and behind the scenes uses &lt;a class="reference external" href="https://d3js.org/"&gt;d3.js&lt;/a&gt; for low-level drawing;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/jovyan/pythreejs"&gt;pythreejs&lt;/a&gt;: this exposes the API of the &lt;cite&gt;three.js&lt;/cite&gt; Javascript/WebGL 3D library to Python; this is a low-level API, not a Python plotting library.&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/ellisonbg/ipyleaflet"&gt;ipyleaflet&lt;/a&gt;: a GIS plotting library that uses ipywidgets and the &lt;a class="reference external" href="http://leafletjs.com/"&gt;Leaflet&lt;/a&gt; Javascript library.&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/jupyter-widgets/widget-cookiecutter"&gt;widget-cookiecutter&lt;/a&gt;: a template for creating custom ipywidgets.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The current version of ipywidgets, released since the workshop, includes some interesting developments: much more of the code is now written in Javascript (actually Typescript) rather than Python so widgets state is maintained in JavaScript-land: widgets can therefore now be rendered and manipulated without a Jupyter kernel!  See &lt;a class="reference external" href="http://nbviewer.jupyter.org/github/ipython/ipywidgets/blob/master/docs/source/examples/Widget%20List.ipynb"&gt;this statically-rendered Notebook&lt;/a&gt; on GitHub as an example.  Another advantage of migrating the bulk of the code to Javascript is that the widgets should be usable with kernel languages other than Python such as R (once people have written language-specific ipywidgets backends).&lt;/p&gt;
&lt;p&gt;Separate to ipywidgets, we were also introduced to &lt;a class="reference external" href="https://www.logilab.org/blogentry/8541176"&gt;SciviJS&lt;/a&gt;, a tool currently being developed by &lt;a class="reference external" href="https://twitter.com/Renou_Martin"&gt;Martin Renou&lt;/a&gt; at &lt;a class="reference external" href="https://www.logilab.org/"&gt;LogiLab&lt;/a&gt; for &lt;strong&gt;visualising 3D mesh-based geometries in a Juypter Notebook&lt;/strong&gt;.  It uses also uses &lt;a class="reference external" href="https://www.khronos.org/webgl/"&gt;WebGL&lt;/a&gt; / &lt;a class="reference external" href="https://threejs.org/"&gt;three.js&lt;/a&gt; for rendering so is rather performant.  I can see some ex-colleagues in civil engineering really liking this.  Check out the &lt;a class="reference external" href="https://demo.logilab.fr/SciviJS/"&gt;online demo&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="numbas-for-online-computer-aided-assessment-cas"&gt;
&lt;h2&gt;Numbas for online computer-aided assessment (CAS)&lt;/h2&gt;
&lt;p&gt;&lt;a class="reference external" href="http://www.numbas.org.uk/"&gt;Numbas&lt;/a&gt; is a open web-based system for formative and summative maths and science tests.  It is being developed by &lt;a class="reference external" href="http://somethingorotherwhatever.com/"&gt;Christian Lawson-Perfect&lt;/a&gt; from the University of Newcastle's &lt;a class="reference external" href="http://www.ncl.ac.uk/maths/outreach/elearning/#overview"&gt;Maths and Stats E-Learning unit&lt;/a&gt;.  It's very different to teaching environments that use Jupyter (e.g. &lt;a class="reference external" href="https://cloud.sagemath.com/"&gt;SageMathCloud&lt;/a&gt;) as almost all the code is self-contained HTML+Javascript that is run on the client (for scalability and resilience) and it is for generating closed tests (rather than open mathematical exercises).  Looks very attractive and intuitive from the user's perspective!&lt;/p&gt;
&lt;p&gt;Christian also mentioned &lt;a class="reference external" href="http://up-for-grabs.net/"&gt;Up For Grabs&lt;/a&gt;, a site of projects wanting help on simpler tasks.  He says it's a good and simple way of getting less experienced developers involved with open-source projects.  As a project maintainer you upload some blurb about your project and tell the site which GitHub Issue tag(s) indicate smaller tasks that are 'up for grabs'.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="case-studies-of-jupyter-usage"&gt;
&lt;h2&gt;Case studies of Jupyter usage&lt;/h2&gt;
&lt;p&gt;&lt;a class="reference external" href="http://www.southampton.ac.uk/~fangohr/"&gt;Hans Fangohr&lt;/a&gt; from the &lt;a class="reference external" href="http://cmg.soton.ac.uk/"&gt;University of Southampton&lt;/a&gt; reported on using Python and Jupyter to encapsulate multi-stage micro-magnetism modelling workflows:
his team have been able to automate the generation of input files and processing of output files for/from old but robust modelling software (&lt;a class="reference external" href="http://math.nist.gov/oommf/"&gt;OOMMF&lt;/a&gt;);
Jupyter then further masks away the complexities of running models.&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://www.sheffield.ac.uk/physics/contacts/mark-quinn"&gt;Mark Quinn&lt;/a&gt; then talked about the impact that &lt;a class="reference external" href="https://cloud.sagemath.com/"&gt;SageMathCloud&lt;/a&gt;, an online teaching environment which uses Jupyter, has had on the teaching of physics, astronomy and coding at the University of Sheffield.  He's been working with Mike Croucher to develop SageMathCloud courses for the Physics department with the goal of introducing effective programming tuition early in undergraduate Physics degree programmes.  He's now quite a fan of the used coding environment (Jupyter) and SageMathCloud's courseware tools (chat facilities and mechanisms for setting and grading assignments) but has now been using it long enough to identify some challenges/issues too (e.g. students getting confused about the order of execution of cells; students opening many notebooks at once (each of which has a resource footprint).&lt;/p&gt;
&lt;p&gt;Mark is involved with the Shepherd Group, who research the efficacy of teaching methods and are based in the same Physics department.  They've recently been studying the impact of using the Jupyter Notebook to undergraduate students who had and hadn't studied Physics at A-Level.  They tested students (at different levels of &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Bloom%27s_taxonomy"&gt;Bloom's Taxonomy&lt;/a&gt;) before and after teaching and concluded that the Notebooks were suitable for aiding students, regardless of whether they had a Physics background.  Hopefully the &lt;a class="reference external" href="https://www.software.ac.uk/"&gt;Software Sustainability Institute&lt;/a&gt; can lend their support to pedagogical studies of this nature in future.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="other-talks"&gt;
&lt;h2&gt;Other talks&lt;/h2&gt;
&lt;p&gt;I should note that there were also a number of other talks that focussed on the &lt;a class="reference external" href="https://www.gap-system.org/"&gt;GAP&lt;/a&gt; and &lt;a class="reference external" href="http://www.sagemath.org/"&gt;SageMath&lt;/a&gt; computational mathematics software packages:
I've deliberately not mentioned them here
so as not to expose my lack of understanding of group theory and semi-groups
and also this post is long enough already!
See the &lt;a class="reference external" href="http://opendreamkit.org/meetings/2017-01-16-ICMS/programme/"&gt;full programme&lt;/a&gt; for info on things I've neglected plus links to the presentations.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="coding-sprints-inc-jupyter-interactions-gallery"&gt;
&lt;h2&gt;Coding Sprints (inc. Jupyter Interactions gallery)&lt;/h2&gt;
&lt;p&gt;After lunch on each of the five days of the workshop we worked on various coding sprints:
some wrote a Jupyter kernel for GAP,
others worked on SageMath,
whilst me and a few others started work on &lt;a class="reference external" href="https://github.com/mikecroucher/jupyter-interactions"&gt;Jupyter Interactions&lt;/a&gt;.
This sprint was suggested by Mike Croucher:
he thought it would be nice to have a curated set of Notebooks that
demonstrate how to use different &lt;a class="reference external" href="https://ipywidgets.readthedocs.io/en/latest/"&gt;ipywidgets&lt;/a&gt; to manipulate various mathematical objects.
Several of us wrote Notebooks while
&lt;a class="reference external" href="http://somethingorotherwhatever.com/"&gt;Christian Lawson-Perfect&lt;/a&gt; quickly put together a very nice &lt;a class="reference external" href="https://github.com/christianp/jupyter-interactions-site"&gt;gallery-generating front end&lt;/a&gt;:&lt;/p&gt;
&lt;div class="figure align-center"&gt;
&lt;img alt="Jupyter Interactions Notebook gallery" src="http://rse.shef.ac.uk/images/jupyter-interactions.png"&gt;
&lt;p class="caption"&gt;Jupyter Interactions Notebook gallery.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;See the &lt;a class="reference external" href="https://mikecroucher.github.io/jupyter-interactions/"&gt;end result here&lt;/a&gt;.
Should you wish to submit your own Jupyter Interactions Notebook then
please &lt;a class="reference external" href="https://github.com/mikecroucher/jupyter-interactions/pulls"&gt;submit a pull request&lt;/a&gt;!&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="culture"&gt;
&lt;h2&gt;Culture&lt;/h2&gt;
&lt;p&gt;This was the first time I'd been to a conference where the emphasis was very much on sharing ideas and working together:
the academic conferences I'd attended prior to this had previously had an air of competition about them.
Looking forward to meeting up with the OpenDreamKit gang again!&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;</description><category>conference</category><guid>http://rse.shef.ac.uk/blog/icms-2017/</guid><pubDate>Sun, 12 Mar 2017 22:00:00 GMT</pubDate></item></channel></rss>