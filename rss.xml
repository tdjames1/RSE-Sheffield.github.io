<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="assets/xml/rss.xsl" media="all"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>RSE at Sheffield</title><link>http://rse.shef.ac.uk/</link><description>RSE at Sheffield</description><atom:link href="http://rse.shef.ac.uk/rss.xml" type="application/rss+xml" rel="self"></atom:link><language>en</language><lastBuildDate>Mon, 12 Sep 2016 09:37:43 GMT</lastBuildDate><generator>https://getnikola.com/</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Accelerated versions of R for Iceberg</title><link>http://rse.shef.ac.uk/blog/intel-R-iceberg/</link><dc:creator>Mike Croucher</dc:creator><description>&lt;div&gt;&lt;p&gt;&lt;strong&gt;To Long; Didn't Read -- Summary&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I've built a version of R on Iceberg that is faster than the standard version for various operations. Documentation is at &lt;a href="http://docs.iceberg.shef.ac.uk/en/latest/software/apps/intel_r.html"&gt;http://docs.iceberg.shef.ac.uk/en/latest/software/apps/intel_r.html&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If it works more quickly for you, or if you have problems, please let us know by emailing &lt;a href="mailto:rse@sheffield.ac.uk"&gt;rse@sheffield.ac.uk&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Background&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I took over building &lt;a href="http://docs.iceberg.shef.ac.uk/en/latest/software/apps/r.html"&gt;R for Iceberg&lt;/a&gt;, Sheffield's High Performance Computing System, around a year ago and have been incrementally improving both the install and the documentation with every release. Something that's been bothering me for a while is the lack of optimisation. The standard Iceberg build uses an ancient version of the gcc compiler and (probably) unoptimised versions of &lt;a href="https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms"&gt;BLAS&lt;/a&gt; and &lt;a href="https://en.wikipedia.org/wiki/LAPACK"&gt;LAPCK&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;BLAS and LAPACK are extremely important libraries -- they provide the code that programs such as R use for linear algebra: Matrix-Matrix multiplication, Cholesky decomposition, principle component analysis and so on. It's important to note that there are lots of implementations of BLAS and LAPACK: &lt;a href="http://math-atlas.sourceforge.net/"&gt;ATLAS&lt;/a&gt;, &lt;a href="http://www.openblas.net/"&gt;OpenBLAS&lt;/a&gt; and the &lt;a href="https://software.intel.com/en-us/intel-mkl"&gt;Intel MKL&lt;/a&gt; are three well-known examples. Written in Fortran, the interfaces of all of these versions are identical, which means you can use them interchangeably, but the speed of the implementation can vary considerably.&lt;/p&gt;
&lt;p&gt;The BLAS and LAPACK implementations on Iceberg are undocumented (before my time!) which means that we have no idea what we are dealing with. Perhaps they are optimised, perhaps not. I suspected 'not'.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Building R with the Intel Compiler and MKL&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The Intel Compiler Suite often produces the fastest executables of all available compilers for any given piece of Fortran or C/C++ code. Additionally, the Intel MKL is probably the fastest implementation of BLAS and LAPACK available for Intel Hardware. As such, I've had &lt;strong&gt;Build R using Intel Compilers and MKL&lt;/strong&gt; on my to-do list for some time.&lt;/p&gt;
&lt;p&gt;Following a recent visit to the University of Lancaster, where they've been doing this for a while, I finally bit the bullet and produced some build-scripts. Thanks to Lancaster's Mike Pacey for help with this!  There are two versions (links point to the exact commits that produced the builds used in this article):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/mikecroucher/HPC_Installers/blob/ea4a9f33b705a8cae01841d9c173278fcb486061/apps/R/3.3.1/sheffield/iceberg/intel_15/install_intel_r_sequential.sh"&gt;install_intel_r_sequential.sh&lt;/a&gt; - Linked to the sequential (i.e. single-core) version of Intel MKL.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/mikecroucher/HPC_Installers/blob/ea4a9f33b705a8cae01841d9c173278fcb486061/apps/R/3.3.1/sheffield/iceberg/intel_15/install_intel_r_parallel.sh"&gt;install_intel_r_parallel.sh&lt;/a&gt; - Linked to the parallel version of Intel MKL.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The benchmark code is available in the Sheffield HPC examples repo &lt;a href="https://github.com/mikecroucher/HPC_Examples/"&gt;https://github.com/mikecroucher/HPC_Examples/&lt;/a&gt;. The exact commit that produced these results is &lt;a href="https://github.com/mikecroucher/HPC_Examples/blob/35de11e7c47bc278b15a64fb77c5575b074e1a47/languages/R/linear_algebra/linear_algebra_bench.r"&gt;35de11e&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Testing&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;It's no good having fast builds of R if they give the wrong results! To make sure that everything is OK, I ran R's installation test suite and everything passed. If you have an account on iceberg, you can see the output from the test suite at &lt;code&gt;/usr/local/packages6/apps/intel/15/R/sequential-3.3.1/install_logs/make_install_tests-R-3.3.1.log&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;It's important to note that although the tests passed, there &lt;strong&gt;are&lt;/strong&gt; differences in output between this build and the reference build that R's test suite is based on. This is due to a number of factors such as the fact that &lt;a href="http://www.walkingrandomly.com/?p=5380"&gt;Floating point addition is not associative&lt;/a&gt; and that the signs of eigenvectors are arbitrary and so on.&lt;/p&gt;
&lt;p&gt;A discussion around these differences and how they relate to R can be found &lt;a href="http://r.789695.n4.nabble.com/quot-make-check-quot-fails-on-lapack-R-and-stats-Ex-R-td4698672.html"&gt;on nabble&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How fast is it?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;So is it worth it? I ran a benchmark called &lt;a href="https://github.com/mikecroucher/HPC_Examples/blob/35de11e7c47bc278b15a64fb77c5575b074e1a47/languages/R/linear_algebra/linear_algebra_bench.r#L19"&gt;linear_algebra_bench.r&lt;/a&gt; that implemented 5 tests&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;MatMul - Multiplies two random 1000 x 5000 matrices together&lt;/li&gt;
&lt;li&gt;Chol - Cholesky decomposition of a 5000 x 5000 random matrix&lt;/li&gt;
&lt;li&gt;SVD - Singular Value Decompisition of a 10000 x 2000 random matrix&lt;/li&gt;
&lt;li&gt;PCA - Principle component analysis of a 10000 x 2000 random matrix&lt;/li&gt;
&lt;li&gt;LDA - A Linear Discriminant Analysis problem&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Run time of these operations compared to Iceberg's standard install of R is shown in the table below.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Iceberg submission scripts for these can be found in the &lt;a href="https://github.com/mikecroucher/HPC_Examples"&gt;HPC Examples repo&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Execution time in seconds (Mean of 5 independent runs) &lt;/strong&gt;&lt;/p&gt;
&lt;style type="text/css"&gt;
.tg  {border-collapse:collapse;border-spacing:0;}
.tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}
.tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}
.tg .tg-yw4l{vertical-align:top}
&lt;/style&gt;

&lt;table class="tg"&gt;
  &lt;tr&gt;
    &lt;th class="tg-yw4l"&gt;&lt;/th&gt;
    &lt;th class="tg-yw4l"&gt;MatMul&lt;/th&gt;
    &lt;th class="tg-yw4l"&gt;Chol&lt;/th&gt;
    &lt;th class="tg-yw4l"&gt;SVD&lt;/th&gt;
    &lt;th class="tg-yw4l"&gt;PCA&lt;/th&gt;
    &lt;th class="tg-yw4l"&gt;LDA&lt;/th&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td class="tg-yw4l"&gt;Standard R&lt;/td&gt;
    &lt;td class="tg-yw4l"&gt;134.70&lt;/td&gt;
    &lt;td class="tg-yw4l"&gt;20.95&lt;/td&gt;
    &lt;td class="tg-yw4l"&gt;46.56&lt;/td&gt;
    &lt;td class="tg-yw4l"&gt;179.60&lt;/td&gt;
    &lt;td class="tg-yw4l"&gt;132.40&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td class="tg-yw4l"&gt;Intel R with sequential MKL&lt;/td&gt;
    &lt;td class="tg-yw4l"&gt;12.19&lt;/td&gt;
    &lt;td class="tg-yw4l"&gt;2.24&lt;/td&gt;
    &lt;td class="tg-yw4l"&gt;9.13&lt;/td&gt;
    &lt;td class="tg-yw4l"&gt;24.58&lt;/td&gt;
    &lt;td class="tg-yw4l"&gt;31.32&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td class="tg-yw4l"&gt;Intel R with parallel MKL (2 cores)&lt;/td&gt;
    &lt;td class="tg-yw4l"&gt;7.21&lt;/td&gt;
    &lt;td class="tg-yw4l"&gt;1.60&lt;/td&gt;
    &lt;td class="tg-yw4l"&gt;5.43&lt;/td&gt;
    &lt;td class="tg-yw4l"&gt;14.66&lt;/td&gt;
    &lt;td class="tg-yw4l"&gt;23.54&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td class="tg-yw4l"&gt;Intel R with parallel MKL (4 cores)&lt;/td&gt;
    &lt;td class="tg-yw4l"&gt;3.24&lt;/td&gt;
    &lt;td class="tg-yw4l"&gt;1.17&lt;/td&gt;
    &lt;td class="tg-yw4l"&gt;3.34&lt;/td&gt;
    &lt;td class="tg-yw4l"&gt;7.87&lt;/td&gt;
    &lt;td class="tg-yw4l"&gt;20.63&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td class="tg-yw4l"&gt;Intel R with parallel MKL (8 cores)&lt;/td&gt;
    &lt;td class="tg-yw4l"&gt;1.71&lt;/td&gt;
    &lt;td class="tg-yw4l"&gt;0.38&lt;/td&gt;
    &lt;td class="tg-yw4l"&gt;1.99&lt;/td&gt;
    &lt;td class="tg-yw4l"&gt;5.33&lt;/td&gt;
    &lt;td class="tg-yw4l"&gt;15.82&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td class="tg-yw4l"&gt;Intel R with parallel MKL (16 cores)&lt;/td&gt;
    &lt;td class="tg-yw4l"&gt;0.96&lt;/td&gt;
    &lt;td class="tg-yw4l"&gt;0.28&lt;/td&gt;
    &lt;td class="tg-yw4l"&gt;1.60&lt;/td&gt;
    &lt;td class="tg-yw4l"&gt;4.05&lt;/td&gt;
    &lt;td class="tg-yw4l"&gt;13.65&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;&lt;img alt="" src="http://rse.shef.ac.uk/images/matmul_r_intel.png"&gt;&lt;/p&gt;
&lt;p&gt;Another way of viewing these results is to see the speed up compared to the standard install of R. &lt;strong&gt;Even on a single CPU core, the Intel builds are between 4 and 11 times faster than the standard builds&lt;/strong&gt;.  Making use of 16 cores takes this up to &lt;strong&gt;141 times faster in the case of Matrix-Matrix Multiplication&lt;/strong&gt;!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Speed up compared to standard R&lt;/strong&gt;&lt;/p&gt;
&lt;style type="text/css"&gt;
.tg  {border-collapse:collapse;border-spacing:0;}
.tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}
.tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}
.tg .tg-yw4l{vertical-align:top}
&lt;/style&gt;

&lt;table class="tg"&gt;
  &lt;tr&gt;
    &lt;th class="tg-yw4l"&gt; &lt;/th&gt;
    &lt;th class="tg-yw4l"&gt;MatMul&lt;/th&gt;
    &lt;th class="tg-yw4l"&gt;Chol&lt;/th&gt;
    &lt;th class="tg-yw4l"&gt;SVD&lt;/th&gt;
    &lt;th class="tg-yw4l"&gt;PCA&lt;/th&gt;
    &lt;th class="tg-yw4l"&gt;LDA&lt;/th&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td class="tg-yw4l"&gt;Standard R&lt;/td&gt;
    &lt;td class="tg-yw4l"&gt;1&lt;/td&gt;
    &lt;td class="tg-yw4l"&gt;1&lt;/td&gt;
    &lt;td class="tg-yw4l"&gt;1&lt;/td&gt;
    &lt;td class="tg-yw4l"&gt;1&lt;/td&gt;
    &lt;td class="tg-yw4l"&gt;1&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td class="tg-yw4l"&gt;Intel R with sequential MKL&lt;/td&gt;
    &lt;td class="tg-yw4l"&gt;11&lt;/td&gt;
    &lt;td class="tg-yw4l"&gt;9&lt;/td&gt;
    &lt;td class="tg-yw4l"&gt;5&lt;/td&gt;
    &lt;td class="tg-yw4l"&gt;7&lt;/td&gt;
    &lt;td class="tg-yw4l"&gt;4&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td class="tg-yw4l"&gt;Intel R with parallel MKL (2 cores)&lt;/td&gt;
    &lt;td class="tg-yw4l"&gt;19&lt;/td&gt;
    &lt;td class="tg-yw4l"&gt;13&lt;/td&gt;
    &lt;td class="tg-yw4l"&gt;9&lt;/td&gt;
    &lt;td class="tg-yw4l"&gt;12&lt;/td&gt;
    &lt;td class="tg-yw4l"&gt;6&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td class="tg-yw4l"&gt;Intel R with parallel MKL (4 cores)&lt;/td&gt;
    &lt;td class="tg-yw4l"&gt;42&lt;/td&gt;
    &lt;td class="tg-yw4l"&gt;18&lt;/td&gt;
    &lt;td class="tg-yw4l"&gt;14&lt;/td&gt;
    &lt;td class="tg-yw4l"&gt;23&lt;/td&gt;
    &lt;td class="tg-yw4l"&gt;6&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td class="tg-yw4l"&gt;Intel R with parallel MKL (8 cores)&lt;/td&gt;
    &lt;td class="tg-yw4l"&gt;79&lt;/td&gt;
    &lt;td class="tg-yw4l"&gt;55&lt;/td&gt;
    &lt;td class="tg-yw4l"&gt;23&lt;/td&gt;
    &lt;td class="tg-yw4l"&gt;34&lt;/td&gt;
    &lt;td class="tg-yw4l"&gt;8&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td class="tg-yw4l"&gt;Intel R with parallel MKL (16 cores)&lt;/td&gt;
    &lt;td class="tg-yw4l"&gt;141&lt;/td&gt;
    &lt;td class="tg-yw4l"&gt;75&lt;/td&gt;
    &lt;td class="tg-yw4l"&gt;29&lt;/td&gt;
    &lt;td class="tg-yw4l"&gt;44&lt;/td&gt;
    &lt;td class="tg-yw4l"&gt;10&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;Parallel environment&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The type of parallelisation in use here is &lt;a href="http://openmp.org/wp/"&gt;OpenMP&lt;/a&gt;. As such, you need to use Iceberg's openmp environment.  That is, if you want 8 cores (say), add the following to your submission  script&lt;/p&gt;
&lt;pre&gt;
#$ -pe openmp 8
export OMP_NUM_THREADS=8
&lt;/pre&gt;

&lt;p&gt;Using OpenMP limits the number of cores you can use per job to the number available on a single node. At the time of writing, this is 16.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How many cores: Finding the sweet spot&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Note that everything is fastest when using 16 cores! As such, it may be tempting to always use 16 cores for your jobs. This will almost always be a mistake.
It may be that the aspect of your code that's accelerated by this build doesn't account for much of the runtime of your problem. As such, those 16 cores will sit idle most of the time -- wasting resources.  &lt;/p&gt;
&lt;p&gt;You'll also spend a lot longer waiting in the queue for 16 cores than you will for 2 cores which may swap any speed gains.&lt;/p&gt;
&lt;p&gt;You should always perform scaling experiments before deciding how many cores to use for your jobs. Consider the Linear Discriminant Analysis problem, for example. Using just one core, Intel build gives us a 4 times speed-up compared to the standard build. Moving to 8 cores only makes it twice as fast again. As such, if you had lots of these jobs to do, your throughput would be higher running lots of single core jobs compared to lots of 8 core jobs.&lt;/p&gt;
&lt;p&gt;If matrix-matrix multiply dominates your runtime, on the other hand, it may well be worth using 16 cores.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Using this version of R for your own work&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;As a user, there are a few things you need to be aware of with the Intel builds of R so I've created a separate documentation page for them.  This is currently at
&lt;a href="http://docs.iceberg.shef.ac.uk/en/latest/software/apps/intel_r.html"&gt;http://docs.iceberg.shef.ac.uk/en/latest/software/apps/intel_r.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;My recommendation for using these builds is to work through the following procedure&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ensure that your code runs with Iceberg's standard version of R and produce a test result.&lt;/li&gt;
&lt;li&gt;In the first instance, switch to the sequential version of the Intel R build. In the best case, this will just require changing the module. You may also need to install some of your packages since the Intel build has a separate packages directory to the standard build.&lt;/li&gt;
&lt;li&gt;If you see speed-up &lt;strong&gt;and&lt;/strong&gt; the results are consistent with your test result, try the parallel version. Initially start with 2 cores and move upwards to find the sweet spot.&lt;/li&gt;
&lt;/ul&gt;&lt;/div&gt;</description><guid>http://rse.shef.ac.uk/blog/intel-R-iceberg/</guid><pubDate>Mon, 12 Sep 2016 00:31:35 GMT</pubDate></item><item><title>The University of Sheffield named an NVIDIA GPU Education Center</title><link>http://rse.shef.ac.uk/blog/the-university-of-sheffield-named-an-nvidia-gpu-education-center/</link><dc:creator>Paul Richmond</dc:creator><description>&lt;div&gt;&lt;p&gt;&lt;img src="http://rse.shef.ac.uk/images/NVIDIA_education.jpg" alt="Sheffield NVIDIA Education Centre" align="right" width="20%"&gt;&lt;/p&gt;
&lt;p&gt;This week I am very pleased to announce that the University of Sheffield has been awarded the status of an NVIDIA CUDA Education Centre.&lt;/p&gt;
&lt;p&gt;The faculty of Engineering has featured this in its latest &lt;a href="http://www.sheffield.ac.uk/faculty/engineering/news/nvidia-1.587003"&gt;faculty newsletter&lt;/a&gt; and the Department of Computer Science has published more details in a &lt;a href="http://www.sheffield.ac.uk/dcs/latest-news/nvidia-1.587214"&gt;news feature&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;But what does this mean to the RSE community at Sheffield and beyond?&lt;/h3&gt;
&lt;p&gt;The recognition of being an NVIDIA education centre is a reflection of the teaching that is provided by The University of Sheffield on the subject of GPU computing. In case you are unaware of what teaching there is, I have a 4th year and Masters teaching module &lt;a href="http://paulrichmond.shef.ac.uk/teaching/COM4521/"&gt;COM4521/COM6521&lt;/a&gt; which ran for the first time in the 2015/2016 Spring Semester. This course will be run annually and is open to research staff as well as taught students. Last time there was roughly a 50:50 mix including senior research staff and PhD students. It is much more involved that the one or two day courses which typically give only an introduction to GPU programming. If you are a researcher looking to exploit GPU performance in your research then this course is an opportunity to learn some new skills.&lt;/p&gt;
&lt;p&gt;In the future this course will be made freely available so even researchers outside of The University of Sheffield will be able to go through the notes and worked examples (lab sheets). &lt;/p&gt;
&lt;p&gt;Some of the other benefits of being an NVIDIA Eduction (and also an NVIDIA Research) centre are;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Access to NVIDIA GPU hardware and software (via Iceberg and in the Diamond labs) &lt;/li&gt;
&lt;li&gt;Significant discount on Tesla hardware purchases&lt;/li&gt;
&lt;li&gt;Access to NVIDIA parallel programming experts and resources&lt;/li&gt;
&lt;li&gt;Access to educational webinars and an array of teaching materials&lt;/li&gt;
&lt;li&gt;Free in the cloud GPU programming training at &lt;a href="https://nvidia.qwiklab.com/"&gt;nvidia.qwiklab.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Support in the form of letters of support (with contributions in kind) for research proposals with emphasis on GPU computing or deep learning&lt;/li&gt;
&lt;li&gt;Joint promotion, public relations, and press activities with NVIDIA&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Other Training Opportunities&lt;/h3&gt;
&lt;p&gt;Through &lt;a href="http://rse.shef.ac.uk/"&gt;RSE Sheffield&lt;/a&gt; and &lt;a href="http://gpucomputing.sites.sheffield.ac.uk"&gt;GPUComputing@Sheffield&lt;/a&gt; shorter courses for GPU computing are also available. I will be announcing dates for 1-2 day CUDA courses shortly and am working with CICS in developing new Python CUDA material. &lt;/p&gt;
&lt;p&gt;For those that missed the sign-up, we are also running a two day deep learning with GPUs course in July. The places for this were in high demand and filled up within a day. This course will be repeated in due time and material from the course will be made available off-line.&lt;/p&gt;
&lt;p&gt;Other GPU announcements will be made on both this RSE blog and on the &lt;a href="https://groups.google.com/a/sheffield.ac.uk/forum/#!forum/gpucomputing"&gt;GPUComputing@Sheffield mailing list&lt;/a&gt;. Expect some exciting new hardware and software once the Iceberg upgrade is complete (shortly).&lt;/p&gt;
&lt;p&gt;Paul&lt;/p&gt;&lt;/div&gt;</description><guid>http://rse.shef.ac.uk/blog/the-university-of-sheffield-named-an-nvidia-gpu-education-center/</guid><pubDate>Sat, 02 Jul 2016 16:50:04 GMT</pubDate></item><item><title>NAG Fortran Compiler 6.1 released</title><link>http://rse.shef.ac.uk/blog/NAG_6_1/</link><dc:creator>Mike Croucher</dc:creator><description>&lt;div&gt;&lt;p&gt;All members of the University are entitled to download and use the NAG Fortran Compiler under the terms of our site license.&lt;/p&gt;
&lt;p&gt;Version 6.1 has just been released:&lt;/p&gt;
&lt;p&gt;&lt;img alt="NAG Fortran Compiler Screenshot" src="http://rse.shef.ac.uk/images/macFB2a.PNG"&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Details at &lt;a href="http://www.nag.co.uk/nag-compiler"&gt;http://www.nag.co.uk/nag-compiler&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Download at &lt;a href="http://www.nag.co.uk/content/downloads-nag-fortran-compiler-versions"&gt;http://www.nag.co.uk/content/downloads-nag-fortran-compiler-versions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Obtain licenses from &lt;strong&gt;support@nag.co.uk&lt;/strong&gt; - Ensure that you email them from your @Sheffield.ac.uk email address&lt;/li&gt;
&lt;/ul&gt;&lt;/div&gt;</description><guid>http://rse.shef.ac.uk/blog/NAG_6_1/</guid><pubDate>Thu, 16 Jun 2016 13:50:28 GMT</pubDate></item><item><title>High Performance Computing with Maple, Part 1</title><link>http://rse.shef.ac.uk/blog/HPC-Maple-1/</link><dc:creator>Mike Croucher</dc:creator><description>&lt;div&gt;&lt;p&gt;Many people who use &lt;a href="http://www.maplesoft.com/"&gt;Maple&lt;/a&gt; on Sheffield's High Performance Computing (HPC) cluster do so interactively. They connect to the system, start a graphical X-Windows session and use Maple in exactly the same way as they would use it on their laptop. Such usage does have some benefits: giving access to more CPU cores and memory than you'd get on even the most highly specified of laptops, for example.&lt;/p&gt;
&lt;p&gt;Interactive usage on the HPC system also has problems. Thanks to &lt;a href="https://en.wikipedia.org/wiki/Latency_(engineering)"&gt;network latency&lt;/a&gt;, using a Graphical User Interface over an X-Windows connection can be a painful experience. Additionally, long calculations can tie up your computer for hours or days and if anything happens to the network connection during that time, you risk losing it all!&lt;/p&gt;
&lt;p&gt;If you spend a long time waiting for your Maple calculations to run, it's probably time to think about moving to batch processing.&lt;/p&gt;
&lt;h3&gt;Batch processing&lt;/h3&gt;
&lt;p&gt;The idea behind batch processing is that you log in to the system, send your computation to a queue and then log out and get on with your life. The HPC system will process your computation when resources become available and email you when it's done. You can then log back in, transfer the results to your laptop and continue your analysis.&lt;/p&gt;
&lt;p&gt;So, batch processing frees up your personal computer but it can also significantly increase your throughput. With batch processing, you can submit hundreds of computations to the queue simultaneously.  The system will automatically process as many of them as it can in parallel -- allowing you to make use of dozens of large computers at once.&lt;/p&gt;
&lt;p&gt;Batch processing is powerful but it comes at a price and that price is complexity.&lt;/p&gt;
&lt;h3&gt;Converting interactive worksheets to Maple language files&lt;/h3&gt;
&lt;p&gt;You are probably used to interacting with Maple via richly formatted worksheets and documents. These have the file extension &lt;strong&gt;.mw&lt;/strong&gt; or &lt;strong&gt;.maple&lt;/strong&gt;. Unfortunately, it is not possible to run Maple worksheets in batch mode so it is necessary for us to convert them to &lt;strong&gt;maple language files&lt;/strong&gt; instead.&lt;/p&gt;
&lt;p&gt;A &lt;a href="http://www.maplesoft.com/support/help/maple/view.aspx?path=Formats%2FMPL"&gt;Maple Language File&lt;/a&gt; has the extension &lt;strong&gt;.mpl&lt;/strong&gt; and is a pure text file. To convert a worksheet to a Maple Language File, open the worksheet and click on  &lt;strong&gt;File-&amp;gt;Export As-&amp;gt;Maple Input&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="Convert to mpl" src="http://rse.shef.ac.uk/images/convert_to_mpl.png"&gt;&lt;/p&gt;
&lt;h3&gt;An example&lt;/h3&gt;
&lt;p&gt;Here is an example &lt;strong&gt;.maple&lt;/strong&gt; worksheet and the corresponding &lt;strong&gt;.mpl&lt;/strong&gt; Maple Language File, created using the conversion process detailed above. We also have a &lt;strong&gt;Job submission script&lt;/strong&gt; that will be explained later.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://rse.shef.ac.uk/maple/hpc1/series_example.maple"&gt;series_example.maple&lt;/a&gt; - Original Maple worksheet&lt;/li&gt;
&lt;li&gt;&lt;a href="http://rse.shef.ac.uk/maple/hpc1/series_example.mpl"&gt;series_example.mpl&lt;/a&gt; - Maple Language File&lt;/li&gt;
&lt;li&gt;&lt;a href="http://rse.shef.ac.uk/maple/hpc1/run_maple_job.sh"&gt;run_maple_job.sh&lt;/a&gt; - Job submission script&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you look at the &lt;strong&gt;.mpl&lt;/strong&gt; file in a text editor, you will see that it contains plain text versions of all the Maple input commands that were present in the original worksheet.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;myseries := series(sin(x), x = 0, 10);
poly := convert(myseries, polynom);
plot(poly, x = -2*Pi .. 2*Pi, y = -3 .. 3);
&lt;/pre&gt;


&lt;p&gt;This is the file that we can run on the HPC system in batch mode.&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;job submission script&lt;/strong&gt; is a set of instructions to the HPC system's scheduler. It tells the system how much memory you want to use, what program you want to run and so on.  Here is its contents&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;!/bin/bash
# Request 4 gigabytes of real memory (mem)
# and 4 gigabytes of virtual memory (mem)
#$ -l mem=4G -l rmem=4G

#Make Maple 2015 available
module load apps/binapps/maple/2015

#Run Maple with the input file, **series_example.mpl**
maple &amp;lt; series_example.mpl
&lt;/pre&gt;


&lt;p&gt;To run the example on the system:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Transfer &lt;strong&gt;series_example.mpl&lt;/strong&gt; and &lt;strong&gt;run_maple_job.sh&lt;/strong&gt; to a directory on the HPC system. They both need to be in the same directory.&lt;/li&gt;
&lt;li&gt;Log in to the system using a command line terminal and &lt;strong&gt;cd&lt;/strong&gt; to the directory containing the files.&lt;/li&gt;
&lt;li&gt;Use the &lt;strong&gt;ls&lt;/strong&gt; command to confirm you really are in the right directory. You should see something like this:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;[ab1test@testnode02 maple_example]$ ls

run_maple_job.sh  series_example.maple  series_example.mpl
&lt;/pre&gt;


&lt;ul&gt;
&lt;li&gt;Submit the job to the queue with the &lt;strong&gt;qsub&lt;/strong&gt; command&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;qsub run_maple_job.sh
&lt;/pre&gt;


&lt;ul&gt;
&lt;li&gt;You should see something like&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;[ab1test@testnode02 maple_example]$ qsub run_maple_job.sh

Your job 1734126 ("run_maple_job.sh") has been submitted
&lt;/pre&gt;


&lt;p&gt;The job number will differ from the one above. It is automatically allocated by the system and uniquely identifies the job.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;At this point, you could log off the system and do something else if you wished but, since this is such a short job, it won't be long before the results appear. A few seconds to a minute under normal conditions.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run the &lt;strong&gt;ls&lt;/strong&gt; command again to see the results files.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;[fe1mpc@testnode02 maple_example]$ ls

run_maple_job.sh  run_maple_job.sh.e1734126  run_maple_job.sh.o1734126  series_example.maple  series_example.mpl
&lt;/pre&gt;


&lt;p&gt;There are two new files:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;run_maple_job.sh.e1734126 - contains any error messages. Hopefully empty here&lt;/li&gt;
&lt;li&gt;run_maple_job.sh.o1734126 - Contains the results of your job&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The numbers at the end refer to the job number.&lt;/p&gt;
&lt;p&gt;This completes your first batch submission using Maple.&lt;/p&gt;
&lt;h3&gt;Issues with graphs in Maple batch mode&lt;/h3&gt;
&lt;p&gt;The Maple worksheet we used in this example includes a plot command. This looks great in a Maple worksheet but looks very retro when performed in batch mode!&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&amp;gt; plot(poly, x = -2*Pi .. 2*Pi, y = -3 .. 3);

                                      3+                                 H     
                                       +                                 H     
                                       +                                HH     
                                      2+                                H      
                                       +                                H      
                                       +                               HH      
                                       +                               H       
                                      1+    HHHHHHHHHH                 H       
           HHHHHHHH                    +  HHH         HHH             H        
          HH      HHH                  +HHH             HH           HH        
  --+-+-+-*+-+--+-+-**-+-+--+-+-+--+-+-**-+-+--+-+-+--+-+-**-+-+--+-+*-+-+-+--
   -6    H     -4     HH   -2        H0*           2       HHH 4    HH     6   
         H             HHH         HHH +                     HHHHHHHH          
        H                 HHHHHHHHHH -1+                                       
        H                              +                                       
       HH                              +                                       
       H                               +                                       
       H                             -2+                                       
       H                               +                                       
      H                                +                                       
      H                              -3+                                       
&lt;/pre&gt;


&lt;p&gt;You probably want to have something that looks a little nicer. The way to do this is to modify the Maple plot command so that it specifies an output file. For example, if we want to create a .gif file, our Maple Language File becomes&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;myseries := series(sin(x), x = 0, 10);
poly := convert(myseries, polynom);

plotsetup(gif,plotoutput="plot.gif"):
plot(poly, x = -2*Pi .. 2*Pi, y = -3 .. 3);
&lt;/pre&gt;


&lt;p&gt;The &lt;strong&gt;plotsetup&lt;/strong&gt; command can output a number of file types.  See Maple's &lt;a href="http://www.maplesoft.com/support/help/maple/view.aspx?path=plotsetup"&gt;plotsetup documentation&lt;/a&gt; for details.&lt;/p&gt;
&lt;p&gt;A full batch example for you to try is available below&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://rse.shef.ac.uk/maple/hpc2/series_example_fixedplot.mpl"&gt;series_example_fixedplot.mpl&lt;/a&gt; - Maple Language File&lt;/li&gt;
&lt;li&gt;&lt;a href="http://rse.shef.ac.uk/maple/hpc2/run_maple_job_2.sh"&gt;run_maple_job_2.sh&lt;/a&gt; - Job submission script&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The results of transferring these files to the system and submitting with &lt;strong&gt;qsub run_maple_job_2.sh&lt;/strong&gt; should include a file called &lt;strong&gt;plot.gif&lt;/strong&gt; that looks like this&lt;/p&gt;
&lt;p&gt;&lt;img alt="Maple plot" src="http://rse.shef.ac.uk/maple/hpc2/plot.gif"&gt;&lt;/p&gt;
&lt;h3&gt;Future articles&lt;/h3&gt;
&lt;p&gt;In future articles, we'll be looking at how to make use of Maple's parallel computing constructs long with more advanced scheduling tricks that allow us to run 100s of jobs simultaneously. &lt;/p&gt;
&lt;h3&gt;Further reading&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://docs.iceberg.shef.ac.uk/en/latest/using-iceberg/sge.html"&gt;General introduction to batch processing&lt;/a&gt; - From the Iceberg documentation&lt;/li&gt;
&lt;li&gt;&lt;a href="http://docs.iceberg.shef.ac.uk/en/latest/software/scheduler/index.html"&gt;A list of scheduler commands&lt;/a&gt; - &lt;strong&gt;qsub&lt;/strong&gt; is just one example of a scheduler command. Here are a few more.&lt;/li&gt;
&lt;/ul&gt;&lt;/div&gt;</description><guid>http://rse.shef.ac.uk/blog/HPC-Maple-1/</guid><pubDate>Thu, 26 May 2016 11:40:19 GMT</pubDate></item><item><title>Fun with strace</title><link>http://rse.shef.ac.uk/blog/fun-with-strace/</link><dc:creator>David Jones</dc:creator><description>&lt;div&gt;&lt;h3&gt;How I solved a mystery with strace and bash&lt;/h3&gt;
&lt;p&gt;So I'm dabbling with &lt;code&gt;iceberg&lt;/code&gt;, The University of Sheffield's HPC, and
I finally get round to putting my &lt;a href="https://github.com/drj11/dot"&gt;&lt;code&gt;.profile&lt;/code&gt;&lt;/a&gt; on there.
And I remember that I don't like
the way &lt;code&gt;less&lt;/code&gt; clears the screen when I've finished reading a &lt;code&gt;man&lt;/code&gt; page.&lt;/p&gt;
&lt;p&gt;I need to set my &lt;code&gt;LESS&lt;/code&gt; environment variable to &lt;code&gt;-X&lt;/code&gt;.
So I &lt;a href="https://github.com/drj11/dot/commit/7d097ba875e2cca186b8d659d3510c2af5c8df1b"&gt;add that to my &lt;code&gt;.profile&lt;/code&gt;&lt;/a&gt;.
I do &lt;code&gt;exec bash -l&lt;/code&gt; to emulate logging back in.&lt;/p&gt;
&lt;p&gt;Doesn't work.
Still clears screen when reading man pages.
Turns out &lt;code&gt;LESS&lt;/code&gt; isn't set.
What is going wrong with my &lt;code&gt;.profile&lt;/code&gt;?&lt;/p&gt;
&lt;p&gt;I'm becoming a fan of &lt;code&gt;strace&lt;/code&gt; for this sort of debugging.&lt;/p&gt;
&lt;p&gt;Have a look at this. When I run this command:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;strace -e signal= -e open bash -l -c 'echo SCRIPT GOT HERE'
&lt;/pre&gt;


&lt;p&gt;I get this output (long and boring, skip and come back to the
bits I refer to):&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;open("/etc/ld.so.cache", O_RDONLY)      = 3
open("/lib64/libtinfo.so.5", O_RDONLY)  = 3
open("/lib64/libdl.so.2", O_RDONLY)     = 3
open("/lib64/libc.so.6", O_RDONLY)      = 3
open("/dev/tty", O_RDWR|O_NONBLOCK)     = 3
open("/usr/lib/locale/locale-archive", O_RDONLY) = 3
open("/proc/meminfo", O_RDONLY|O_CLOEXEC) = 3
open("/usr/lib64/gconv/gconv-modules.cache", O_RDONLY) = 3
open("/etc/profile", O_RDONLY)          = 3
open("/etc/profile.d/", O_RDONLY|O_NONBLOCK|O_DIRECTORY|O_CLOEXEC) = 3
open("/dev/null", O_WRONLY|O_CREAT|O_TRUNC, 0666) = 3
open("/etc/profile.d/colorls.sh", O_RDONLY) = 3
open("/dev/null", O_WRONLY|O_CREAT|O_TRUNC, 0666) = 3
open("/dev/null", O_WRONLY|O_CREAT|O_TRUNC, 0666) = 3
open("/dev/null", O_WRONLY|O_CREAT|O_TRUNC, 0666) = 3
open("/etc/profile.d/cvs.sh", O_RDONLY) = 3
open("/dev/null", O_WRONLY|O_CREAT|O_TRUNC, 0666) = 3
open("/etc/profile.d/ge.sh", O_RDONLY)  = 3
open("/dev/null", O_WRONLY|O_CREAT|O_TRUNC, 0666) = 3
open("/etc/profile.d/glib2.sh", O_RDONLY) = 3
open("/dev/null", O_WRONLY|O_CREAT|O_TRUNC, 0666) = 3
open("/etc/profile.d/lang.sh", O_RDONLY) = 3
open("/dev/null", O_WRONLY|O_CREAT|O_TRUNC, 0666) = 3
open("/etc/profile.d/less.sh", O_RDONLY) = 3
open("/dev/null", O_WRONLY|O_CREAT|O_TRUNC, 0666) = 3
open("/etc/profile.d/modules.sh", O_RDONLY) = 3
open("/usr/share/Modules/init/bash", O_RDONLY) = 3
open("/usr/share/Modules/init/bash_completion", O_RDONLY) = 3
open("/dev/null", O_WRONLY|O_CREAT|O_TRUNC, 0666) = 3
open("/etc/profile.d/qt.sh", O_RDONLY)  = 3
open("/dev/null", O_WRONLY|O_CREAT|O_TRUNC, 0666) = 3
open("/etc/profile.d/set-bmc-url.sh", O_RDONLY) = 3
open("/dev/null", O_WRONLY|O_CREAT|O_TRUNC, 0666) = 3
open("/etc/profile.d/shef-login.sh", O_RDONLY) = 3
open("/dev/null", O_WRONLY|O_CREAT|O_TRUNC, 0666) = 3
open("/etc/profile.d/udisks-bash-completion.sh", O_RDONLY) = 3
open("/dev/null", O_WRONLY|O_CREAT|O_TRUNC, 0666) = 3
open("/etc/profile.d/vim.sh", O_RDONLY) = 3
open("/dev/null", O_WRONLY|O_CREAT|O_TRUNC, 0666) = 3
open("/usr/share/locale/locale.alias", O_RDONLY) = 3
open("/usr/share/locale/en_GB.UTF-8/LC_MESSAGES/bash.mo", O_RDONLY) = -1 ENOENT (No such file or directory)
open("/usr/share/locale/en_GB.utf8/LC_MESSAGES/bash.mo", O_RDONLY) = -1 ENOENT (No such file or directory)
open("/usr/share/locale/en_GB/LC_MESSAGES/bash.mo", O_RDONLY) = -1 ENOENT (No such file or directory)
open("/usr/share/locale/en.UTF-8/LC_MESSAGES/bash.mo", O_RDONLY) = -1 ENOENT (No such file or directory)
open("/usr/share/locale/en.utf8/LC_MESSAGES/bash.mo", O_RDONLY) = -1 ENOENT (No such file or directory)
open("/usr/share/locale/en/LC_MESSAGES/bash.mo", O_RDONLY) = -1 ENOENT (No such file or directory)
open("/dev/null", O_WRONLY|O_CREAT|O_TRUNC, 0666) = 3
open("/etc/profile.d/which2.sh", O_RDONLY) = 3
open("/home/md1xdrj/.bash_profile", O_RDONLY) = 3
open("/home/md1xdrj/.bashrc", O_RDONLY) = 3
open("/etc/bashrc", O_RDONLY)           = 3
open("/etc/profile.d/modules.sh", O_RDONLY) = 3
open("/usr/share/Modules/init/bash", O_RDONLY) = 3
open("/usr/share/Modules/init/bash_completion", O_RDONLY) = 3
SCRIPT GOT HERE
+++ exited with 0 +++
&lt;/pre&gt;


&lt;p&gt;&lt;code&gt;strace&lt;/code&gt; runs a command and &lt;em&gt;traces&lt;/em&gt; the &lt;em&gt;system calls&lt;/em&gt;
(so I suppose &lt;code&gt;strace&lt;/code&gt; is short for &lt;strong&gt;S&lt;/strong&gt;ystem &lt;strong&gt;Trace&lt;/strong&gt;).
I'm running the command line &lt;code&gt;bash -l -c 'echo SCRIPT GOT HERE'&lt;/code&gt; under &lt;code&gt;strace&lt;/code&gt;.
&lt;code&gt;bash -l&lt;/code&gt; is a &lt;em&gt;login&lt;/em&gt; shell, so it should source my &lt;code&gt;.profile&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;First thing to notice about running things with &lt;code&gt;strace&lt;/code&gt; is that you get lots of output.
And that's after I've used two options to reduce the ammount of output.
The &lt;code&gt;-e open&lt;/code&gt; option to &lt;code&gt;strace&lt;/code&gt; restricts it so that it only shows &lt;code&gt;open()&lt;/code&gt; system calls;
normally it will show all system calls, which is &lt;em&gt;way&lt;/em&gt; more output.
The &lt;code&gt;-e signal=&lt;/code&gt; option to &lt;code&gt;strace&lt;/code&gt; means that it won't show any signals, without it you see all signals.
Most programs don't see many signals,
but in this case there are a fair number of child process management signals
that are not particularly interesting.&lt;/p&gt;
&lt;p&gt;The first few files are related to C runtimes and dynamic linking (&lt;code&gt;/etc/ld.so.cache&lt;/code&gt;, &lt;code&gt;/lib64/libc.so.6&lt;/code&gt;, and so on).
Then we get &lt;code&gt;/etc/profile&lt;/code&gt;. Aha!
&lt;code&gt;bash&lt;/code&gt; is reading the system wide profile file.
Which it turns out causes it to reading the bag of little profile scripts kept in &lt;code&gt;/etc/profile.d/&lt;/code&gt; (most of which are specific to the Sheffield HPC).&lt;/p&gt;
&lt;p&gt;(I've no idea what the obsession with opening &lt;code&gt;/dev/null&lt;/code&gt; in between every script is by the way; some crazy &lt;code&gt;bash&lt;/code&gt; thing. whatever)&lt;/p&gt;
&lt;p&gt;Then, eventually, near the bottom, we see bash opening &lt;code&gt;/home/md1xdrj/.bash_profile&lt;/code&gt;.
And this is the culprit.
I'm like "wait, WAT!?", "I have a &lt;code&gt;.bash_profile&lt;/code&gt;?"&lt;/p&gt;
&lt;p&gt;It turns out that, yes, I do have a &lt;code&gt;.bash_profile&lt;/code&gt;.
I wasn't expecting that (it wasn't created by me).
A quick perusal of &lt;code&gt;man bash&lt;/code&gt;[*1] reveals that
if &lt;code&gt;~/.bash_profile&lt;/code&gt; exists then it will be sourced and &lt;code&gt;.profile&lt;/code&gt; will not.&lt;/p&gt;
&lt;p&gt;So I remove my &lt;code&gt;~/.bash_profile&lt;/code&gt; and life is good again.&lt;/p&gt;
&lt;h3&gt;Reflection&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;strace&lt;/code&gt; is a great tool and well worth exploring a little bit
(fun fact: you can attach to already running processes with &lt;code&gt;strace -p&lt;/code&gt;).
So in this case I could've read the manual and inspected the file system to see what files &lt;code&gt;bash&lt;/code&gt; would source,
but &lt;code&gt;strace&lt;/code&gt; is more direct.
The manual might be out of date, misunderstood, or just plain wrong.
But &lt;code&gt;strace&lt;/code&gt; cannot lie, it shows me what system calls a tool is actually making.&lt;/p&gt;
&lt;p&gt;The Truth.&lt;/p&gt;
&lt;p&gt;Of course The Truth that &lt;code&gt;strace&lt;/code&gt; provides is really just &lt;em&gt;a&lt;/em&gt; truth.
There is a whole world of complexity that &lt;code&gt;strace&lt;/code&gt; hides from us.
Most obviously, we don't get to see all the instructions
that get executed in between the system calls.
We probably don't want to.
&lt;code&gt;strace&lt;/code&gt; is serving up an abstraction, and that's a useful Truth
to deal with.&lt;/p&gt;
&lt;h3&gt;Fanzine!&lt;/h3&gt;
&lt;p&gt;If you liked this, then you should check out this &lt;a href="http://jvns.ca/blog/2015/04/14/strace-zine/"&gt;strace
fanzine&lt;/a&gt;.
I cannot recommend it enough.
It's enthusiastic, witty, fun to read, and you will learn
something about &lt;code&gt;strace&lt;/code&gt; and system calls (I did!).&lt;/p&gt;
&lt;h3&gt;Footnotes&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;This is what I call "a joke". Everyone should read &lt;code&gt;man bash&lt;/code&gt;, but it is like Joyce's Ulysses: better read the Cliffs Notes[*2].&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;There are no Cliffs Notes for &lt;code&gt;bash&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;/div&gt;</description><guid>http://rse.shef.ac.uk/blog/fun-with-strace/</guid><pubDate>Mon, 23 May 2016 09:26:51 GMT</pubDate></item><item><title>We're hiring - RSE Position on Massive Scale Complex Systems Simulation with Accelerated Computing</title><link>http://rse.shef.ac.uk/blog/RSE_gpu_role_2016/</link><dc:creator>Paul Richmond</dc:creator><description>&lt;div&gt;&lt;p&gt;A new position is available as a Research Associate/Research Software Engineer in the area of complex systems modelling using emerging high performance parallel architectures.&lt;/p&gt;
&lt;p&gt;This post can be configured in two different ways. Either as a 3 year Research Associate/Research Software Engineer only, or as a 5 year post working as a Research Associate/Research Software Engineer (60%) and a Research Software Consultant (40%). Candidateâ€™s preference for either option will be discussed at the interview stage.&lt;/p&gt;
&lt;p&gt;More details on &lt;a class="reference external" href="https://jobs.shef.ac.uk/sap/bc/webdynpro/sap/hrrcf_a_posting_apply?PARAM=cG9zdF9pbnN0X2d1aWQ9NTcxNUQzNTRGNTJCNkM5OEUxMDAwMDAwQUMxRTg4NzgmY2FuZF90eXBlPUVYVA%3d%3d&amp;amp;sap-client=400&amp;amp;sap-language=EN&amp;amp;sap-accessibility=X&amp;amp;sap-ep-themeroot=%2fSAP%2fPUBLIC%2fBC%2fUR%2fuos#"&gt;The University of Sheffield job site&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;</description><guid>http://rse.shef.ac.uk/blog/RSE_gpu_role_2016/</guid><pubDate>Mon, 25 Apr 2016 09:06:12 GMT</pubDate></item><item><title>9 steps for quality research software</title><link>http://rse.shef.ac.uk/blog/9_steps/</link><dc:creator>Mike Croucher</dc:creator><description>&lt;div&gt;&lt;p&gt;I attended the &lt;a class="reference external" href="http://www.software.ac.uk/"&gt;Software Sustainability Institute's&lt;/a&gt; &lt;a class="reference external" href="http://www.software.ac.uk/cw16"&gt;Collaborations Workshop&lt;/a&gt; last month. This annual workshop is one of the primary events in the Research Software Engineering calendar and I highly recommend going to one if you are involved in the development of research software in any way.&lt;/p&gt;
&lt;p&gt;One of the things I worked on was a collaborative blog post called &lt;a class="reference external" href="http://www.software.ac.uk/blog/2016-04-05-9-steps-quality-research-software"&gt;9 steps for quality research software&lt;/a&gt;.  I also wrote an article about some of the work I do called &lt;a class="reference external" href="http://www.walkingrandomly.com/?p=5997"&gt;The accident and emergency of Research Software Engineering.&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;</description><guid>http://rse.shef.ac.uk/blog/9_steps/</guid><pubDate>Mon, 18 Apr 2016 07:54:39 GMT</pubDate></item><item><title>Sheffield RSE team collaborates with lecturers to teach computation</title><link>http://rse.shef.ac.uk/blog/jupyter-for-chem-eng/</link><dc:creator>Mike Croucher</dc:creator><description>&lt;div&gt;&lt;img alt="/images/jupyter.png" src="http://rse.shef.ac.uk/images/jupyter.png"&gt;
&lt;p&gt;Last year, I worked with Dr Marta Milo of the &lt;a class="reference external" href="https://www.sheffield.ac.uk/bms"&gt;Department of Biomedical Science&lt;/a&gt; to develop a &lt;a class="reference external" href="http://opendsi.cc/bioinformatics/"&gt;new course that taught the basics of Bioinformatics&lt;/a&gt; to biology undergraduates. Marta took care of the subject matter while I took care of getting it all to work in the &lt;a class="reference external" href="http://jupyter.org/"&gt;Jupyter Notebook&lt;/a&gt; in &lt;a class="reference external" href="https://cloud.sagemath.com/"&gt;Sage Math Cloud&lt;/a&gt;. I also gave crash courses in Jupyter, git and SageMathCloud to support staff.&lt;/p&gt;
&lt;p&gt;The course was a great success and demonstrated what can be achieved when academics partner with Research Software Engineers to deliver top quality computational teaching. My favourite comment from student feedback was &lt;strong&gt;The hardest thing ever, stressful, frustrating but very rewarding.&lt;/strong&gt; -- welcome to my life!&lt;/p&gt;
&lt;p&gt;This success has led to me being invited to departmental teaching away days for subject areas that include a lot of computation in their syllabus. The most recent of these was with the &lt;a class="reference external" href="http://www.sheffield.ac.uk/cbe"&gt;Department of chemical and biological engineering&lt;/a&gt;. I only had ten minutes but managed to include an introduction to the Sheffield RSE group, a quick demonstration of the Jupyter notebook, a discussion of the benefits of using SageMathCloud instead of the local managed desktop and the possibilities offered by this combination of technologies.&lt;/p&gt;
&lt;p&gt;Sometimes, it's useful to be able to talk quickly!&lt;/p&gt;
&lt;p&gt;Other discussions in the session I was involved with included a fantastic overview of flipped classroom teaching by &lt;a class="reference external" href="http://www.sheffield.ac.uk/cbe/staff/academic/spatwardhan"&gt;Siddharth Patwardhan&lt;/a&gt; and some of the upcoming challenges and opportunities in the higher education teaching sector by &lt;a class="reference external" href="https://www.sheffield.ac.uk/staff/news/pvc-learning-teaching-wyn-morgan-1.453796"&gt;Wyn Morgan&lt;/a&gt;, Sheffield's Pro-Vice-Chancellor for Learning and Teaching.&lt;/p&gt;
&lt;p&gt;Channeling my inner Ferris Beuller, &lt;strong&gt;The world of research software moves pretty fast. If you don't stop and look around for a while, you could miss it&lt;/strong&gt;. It was a pleasure to show off some of my favourite technology to the chemical and biological engineers and I look forward to working with them all in the future.&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Slides from my talk are available at &lt;a class="reference external" href="http://mikecroucher.github.io/ChemEng_Jupyter_talk2016/"&gt;http://mikecroucher.github.io/ChemEng_Jupyter_talk2016/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/div&gt;</description><guid>http://rse.shef.ac.uk/blog/jupyter-for-chem-eng/</guid><pubDate>Mon, 11 Apr 2016 07:26:37 GMT</pubDate></item><item><title>Windows 10 to support Linux binaries</title><link>http://rse.shef.ac.uk/blog/linux-in-windows10-announce/</link><dc:creator>Ian Cottam</dc:creator><description>&lt;div&gt;&lt;p&gt;The big news from Microsoft is that, from this summer, Windows 10 will
support user-mode programs from the popular Ubuntu Linux distribution.&lt;/p&gt;
&lt;p&gt;By "user-mode" we mean non-kernel things or, in other words, anything you
can type into a Bash shell command window. This is complete binary
compatibility: you can, for example, apt-get your favourite Linux tool or
just copy it over from an Ubuntu Linux system and it will run (assuming
you have any libraries it needs).&lt;/p&gt;
&lt;p&gt;The underlying technology is a new Windows' service that dynamically maps
Linux system calls to Windows ones, whilst maintaining the Linux
semantics.&lt;/p&gt;
&lt;p&gt;This is a big step for several reasons; here are just some:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;researchers who currently dual boot their laptops/desktops may not need
to&lt;/li&gt;
&lt;li&gt;researchers who run either Linux or Windows in a virtual machine may not
need to&lt;/li&gt;
&lt;li&gt;staff and students who buy expensive MacBooks mainly for its Unix
sub-system could buy a cheaper Windows 10 based laptop&lt;/li&gt;
&lt;li&gt;as Windows 10 will be binary compatible with Linux it could be said to
have an advantage over Apple Macs which use the BSD version of Unix (as
BSD has numerous, small but sometimes annoying, differences to the tools found on
Linux)&lt;/li&gt;
&lt;li&gt;it makes the path from developing on a laptop to a high-performance
computing cluster much more straightforward (i.e. basically the same Linux
toolset all the way)&lt;/li&gt;
&lt;li&gt;new researchers attending software/data carpentry courses - to learn the
basics of good software engineering - will no longer have to work in a
system alien to their day-to-day computing environment&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I'm sure you can think of others.&lt;/p&gt;
&lt;p&gt;The devil is always in the details, but from reports to-date this is good news for researchers.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Mike Croucher, one of Sheffield's RSE Fellows, writes about the announcement on his blog: &lt;a href="http://www.walkingrandomly.com/?p=6011"&gt;http://www.walkingrandomly.com/?p=6011&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Lots more detail from Microsoft's Scott Hanselman &lt;a href="http://www.hanselman.com/blog/DevelopersCanRunBashShellAndUsermodeUbuntuLinuxBinariesOnWindows10.aspx"&gt;http://www.hanselman.com/blog/DevelopersCanRunBashShellAndUsermodeUbuntuLinuxBinariesOnWindows10.aspx&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/div&gt;</description><guid>http://rse.shef.ac.uk/blog/linux-in-windows10-announce/</guid><pubDate>Wed, 06 Apr 2016 10:25:37 GMT</pubDate></item><item><title>Our first Code Cafe: First steps with R</title><link>http://rse.shef.ac.uk/blog/code-cafe-R/</link><dc:creator>Mike Croucher</dc:creator><description>&lt;div&gt;&lt;p&gt;We ran a 'Code Cafe' event for Coffee Revolution for Researchers who wanted to take their first steps with R. Details and class materials are at &lt;a href="http://www.walkingrandomly.com/?p=5981"&gt;http://www.walkingrandomly.com/?p=5981&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="R Code Cafe" src="http://www.walkingrandomly.com/wp-content/uploads/2016/03/CdIBvyEW8AAIUAA.jpg"&gt;&lt;/p&gt;&lt;/div&gt;</description><guid>http://rse.shef.ac.uk/blog/code-cafe-R/</guid><pubDate>Thu, 10 Mar 2016 19:06:37 GMT</pubDate></item></channel></rss>